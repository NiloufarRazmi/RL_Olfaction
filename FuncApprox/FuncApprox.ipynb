{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f52c5527-938b-48c2-b990-bf4bce0353c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%load_ext lab_black\n",
    "%run utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "223c5f4c-74f1-4170-8a5f-10f3e318128d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Params()"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = Params()\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "396fba7a-9d38-4ba6-af1c-90ceec43fe06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0.,  0.],\n",
       "       [ 1.,  1.,  1.,  0.],\n",
       "       [ 2.,  2.,  2.,  1.],\n",
       "       [ 3.,  3.,  3.,  2.],\n",
       "       [ 4.,  4.,  4.,  3.],\n",
       "       [ 0.,  5.,  5.,  5.],\n",
       "       [ 1.,  6.,  6.,  5.],\n",
       "       [ 2.,  7.,  7.,  6.],\n",
       "       [ 3.,  8.,  8.,  7.],\n",
       "       [ 4.,  9.,  9.,  8.],\n",
       "       [ 5., 10., 10., 10.],\n",
       "       [ 6., 76., 11., 10.],\n",
       "       [ 7., 12., 12., 11.],\n",
       "       [ 8., 13., 13., 12.],\n",
       "       [ 9., 14., 14., 13.],\n",
       "       [10., 15., 15., 15.],\n",
       "       [11., 16., 16., 15.],\n",
       "       [12., 17., 17., 16.],\n",
       "       [13., 18., 18., 17.],\n",
       "       [14., 19., 19., 18.],\n",
       "       [15., 20., 20., 20.],\n",
       "       [16., 21., 21., 20.],\n",
       "       [17., 22., 22., 21.],\n",
       "       [18., 23., 23., 22.],\n",
       "       [19., 24., 24., 23.],\n",
       "       [25., 25., 25., 25.],\n",
       "       [26., 26., 26., 25.],\n",
       "       [27., 27., 27., 26.],\n",
       "       [28., 28., 28., 27.],\n",
       "       [29., 29., 29., 28.],\n",
       "       [25., 30., 30., 30.],\n",
       "       [26., 31., 31., 30.],\n",
       "       [27., 32., 32., 31.],\n",
       "       [28., 33., 33., 32.],\n",
       "       [29., 34., 34., 33.],\n",
       "       [30., 35., 35., 35.],\n",
       "       [31., 36., 36., 35.],\n",
       "       [32., 37., 37., 36.],\n",
       "       [33., 38., 38., 37.],\n",
       "       [34., 39., 39., 38.],\n",
       "       [35., 40., 40., 40.],\n",
       "       [36., 41., 41., 40.],\n",
       "       [37., 42., 42., 41.],\n",
       "       [38., 43., 43., 42.],\n",
       "       [39., 44., 44., 43.],\n",
       "       [40., 45., 45., 45.],\n",
       "       [41., 46., 46., 45.],\n",
       "       [42., 47., 47., 46.],\n",
       "       [43., 48., 48., 47.],\n",
       "       [44., 49., 49., 48.],\n",
       "       [50., 50., 50., 50.],\n",
       "       [51., 51., 51., 50.],\n",
       "       [52., 52., 52., 51.],\n",
       "       [53., 53., 53., 52.],\n",
       "       [54., 54., 54., 53.],\n",
       "       [50., 55., 55., 55.],\n",
       "       [51., 56., 56., 55.],\n",
       "       [52., 57., 57., 56.],\n",
       "       [53., 58., 58., 57.],\n",
       "       [54., 59., 59., 58.],\n",
       "       [55., 60., 60., 60.],\n",
       "       [56., 61., 61., 60.],\n",
       "       [57., 62., 62., 61.],\n",
       "       [58., 63., 63., 62.],\n",
       "       [59., 64., 64., 63.],\n",
       "       [60., 65., 65., 65.],\n",
       "       [61., 66., 66., 65.],\n",
       "       [62., 67., 67., 66.],\n",
       "       [63., 68., 68., 67.],\n",
       "       [64., 69., 69., 68.],\n",
       "       [65., 70., 70., 70.],\n",
       "       [66., 71., 71., 70.],\n",
       "       [67., 72., 72., 71.],\n",
       "       [68., 73., 73., 72.],\n",
       "       [69., 74., 74., 73.],\n",
       "       [75., 75., 75., 75.],\n",
       "       [76., 76., 76., 75.],\n",
       "       [77., 77., 77., 76.],\n",
       "       [78., 78., 78., 77.],\n",
       "       [79., 79., 79., 78.],\n",
       "       [75., 80., 80., 80.],\n",
       "       [76., 81., 81., 80.],\n",
       "       [77., 82., 82., 81.],\n",
       "       [78., 83., 83., 82.],\n",
       "       [79., 84., 84., 83.],\n",
       "       [80., 85., 85., 85.],\n",
       "       [81., 86., 86., 85.],\n",
       "       [82., 87., 87., 86.],\n",
       "       [83., 88., 88., 87.],\n",
       "       [84., 89., 89., 88.],\n",
       "       [85., 90., 90., 90.],\n",
       "       [86., 91., 91., 90.],\n",
       "       [87., 92., 92., 91.],\n",
       "       [88., 93., 93., 92.],\n",
       "       [89., 94., 94., 93.],\n",
       "       [90., 95., 95., 95.],\n",
       "       [91., 96., 96., 95.],\n",
       "       [92., 97., 97., 96.],\n",
       "       [93., 98., 98., 97.],\n",
       "       [94., 99., 99., 98.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = Environment(params)\n",
    "env.transitionList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ce9fbdc-6e34-4d40-9f84-6f622c2b39c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "learner = Qlearning(\n",
    "    learning_rate=params.alpha,\n",
    "    gamma=params.gamma,\n",
    "    state_size=params.numStates,\n",
    "    action_size=params.numActions,\n",
    ")\n",
    "explorer = EpsilonGreedy(epsilon=params.epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cdccf73b-8a52-43b5-96bf-4b68c79ea602",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                     \r"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 26 is out of bounds for axis 0 with size 25",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 16\u001b[0m\n\u001b[1;32m     12\u001b[0m total_rewards \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m done:\n\u001b[0;32m---> 16\u001b[0m     action \u001b[38;5;241m=\u001b[39m \u001b[43mexplorer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchoose_action\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# action_space=env.action_space, state=state, qtable=learner.qtable\u001b[39;49;00m\n\u001b[1;32m     18\u001b[0m \u001b[43m        \u001b[49m\u001b[43maction_space\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqtable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlearner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mqtable\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;66;03m# Take the action (a) and observe the outcome state(s') and reward (r)\u001b[39;00m\n\u001b[1;32m     22\u001b[0m     new_state, reward \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mstep(action, state)\n",
      "File \u001b[0;32m~/Dev/RL_Olfaction/FuncApprox/utils.py:76\u001b[0m, in \u001b[0;36mEpsilonGreedy.choose_action\u001b[0;34m(self, action_space, state, qtable)\u001b[0m\n\u001b[1;32m     72\u001b[0m     action \u001b[38;5;241m=\u001b[39m action_space\u001b[38;5;241m.\u001b[39msample()\n\u001b[1;32m     74\u001b[0m \u001b[38;5;66;03m# Exploitation (taking the biggest Q-value for this state)\u001b[39;00m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 76\u001b[0m     action \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(\u001b[43mqtable\u001b[49m\u001b[43m[\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m action\n",
      "\u001b[0;31mIndexError\u001b[0m: index 26 is out of bounds for axis 0 with size 25"
     ]
    }
   ],
   "source": [
    "rewards = np.zeros((params.numEpisodes, params.n_runs))\n",
    "steps = np.zeros((params.numEpisodes, params.n_runs))\n",
    "episodes = np.arange(params.numEpisodes)\n",
    "\n",
    "for run in range(params.n_runs):  # Run several times to account for stochasticity\n",
    "    for episode in tqdm(\n",
    "        episodes, desc=f\"Run {run}/{params.n_runs} - Episodes\", leave=False\n",
    "    ):\n",
    "        state = env.reset()  # Reset the environment\n",
    "        step = 0\n",
    "        done = False\n",
    "        total_rewards = 0\n",
    "        \n",
    "        while not done:\n",
    "\n",
    "            action = explorer.choose_action(\n",
    "                # action_space=env.action_space, state=state, qtable=learner.qtable\n",
    "                action_space=params.actions, state=state, qtable=learner.qtable\n",
    "            )\n",
    "\n",
    "            # Take the action (a) and observe the outcome state(s') and reward (r)\n",
    "            new_state, reward = env.step(action, state)\n",
    "            done = env.is_terminated(state, action)\n",
    "\n",
    "            learner.qtable[state, action] = learner.update(\n",
    "                state, action, reward, new_state\n",
    "            )\n",
    "\n",
    "            total_rewards += reward\n",
    "\n",
    "            # Our new state is state\n",
    "            state = new_state\n",
    "\n",
    "        # explorer.epsilon = explorer.update_epsilon(episode)\n",
    "\n",
    "        rewards[episode, run] = total_rewards\n",
    "        steps[episode, run] = step"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
