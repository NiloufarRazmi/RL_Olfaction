{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DQN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "54AIvDov_7aa"
   },
   "source": [
    "### Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gxxpHDIs_lvg",
    "outputId": "412c65c1-7c24-4b9a-f5cf-8f98dd648fe4",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import logging\n",
    "import shutil\n",
    "from collections import deque, namedtuple, OrderedDict\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import ipdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gxxpHDIs_lvg",
    "outputId": "412c65c1-7c24-4b9a-f5cf-8f98dd648fe4",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "# from torchinfo import summary\n",
    "\n",
    "# if GPU is to be used\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import plotting\n",
    "\n",
    "# from environment_lights_tensor import (\n",
    "#     WrappedEnvironment,\n",
    "#     Actions,\n",
    "#     CONTEXTS_LABELS,\n",
    "#     OdorCues,\n",
    "#     LightCues,\n",
    "# )\n",
    "from agent_tensor import EpsilonGreedy\n",
    "from environment_tensor import (\n",
    "    CONTEXTS_LABELS,\n",
    "    Actions,\n",
    "    Cues,\n",
    "    WrappedEnvironment,\n",
    "    TriangleState,\n",
    ")\n",
    "from utils import Params, make_deterministic, random_choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gxxpHDIs_lvg",
    "outputId": "412c65c1-7c24-4b9a-f5cf-8f98dd648fe4",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Formatting & autoreload stuff\n",
    "%load_ext lab_black\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# %matplotlib ipympl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gxxpHDIs_lvg",
    "outputId": "412c65c1-7c24-4b9a-f5cf-8f98dd648fe4",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/kir0ul/texlive/2023/bin/x86_64-linux/latex\n"
     ]
    }
   ],
   "source": [
    "sns.set_theme(font_scale=1.5)\n",
    "# plt.style.use(\"ggplot\")\n",
    "print(shutil.which(\"latex\"))\n",
    "USETEX = True if shutil.which(\"latex\") else False\n",
    "mpl.rcParams[\"text.usetex\"] = USETEX\n",
    "if USETEX:\n",
    "    mpl.rcParams[\"font.family\"] = [\"serif\"]\n",
    "else:\n",
    "    mpl.rcParams[\"font.family\"] = [\"sans-serif\"]\n",
    "    mpl.rcParams[\"font.sans-serif\"] = [\n",
    "        \"Fira Sans\",\n",
    "        \"Computer Modern Sans Serif\",\n",
    "        \"DejaVu Sans\",\n",
    "        \"Verdana\",\n",
    "        \"Arial\",\n",
    "        \"Helvetica\",\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "54AIvDov_7aa"
   },
   "source": [
    "### Save directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2024-04-19_16-30-46'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "now = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP_TAG = \"scratch\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save path: `/home/kir0ul/Projects/RL_Olfaction/TriangleTask/save/2024-04-19_16-30-46_scratch`\n"
     ]
    }
   ],
   "source": [
    "ROOT_PATH = Path(\"env\").parent\n",
    "SAVE_PATH = ROOT_PATH / \"save\"\n",
    "folder = f\"{now}_{EXP_TAG}\" if EXP_TAG else now\n",
    "CURRENT_PATH = SAVE_PATH / folder\n",
    "CURRENT_PATH.mkdir(parents=True, exist_ok=True)  # Create the tree of directories\n",
    "print(f\"Save path: `{CURRENT_PATH.absolute()}`\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure logging\n",
    "logfile = CURRENT_PATH / \"training.log\"\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "handler = logging.FileHandler(logfile)\n",
    "formatter = logging.Formatter(\n",
    "    \"%(asctime)s : %(name)s  : %(funcName)s : %(levelname)s : %(message)s\"\n",
    ")\n",
    "handler.setFormatter(formatter)\n",
    "logger.addHandler(handler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "NP28hCqLiVSy"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Params(seed=None, n_runs=1, total_episodes=60, epsilon=0.5, epsilon_min=0.2, epsilon_max=1.0, decay_rate=0.01, epsilon_warmup=100, gamma=0.99, alpha=0.0001, nLayers=5, nHiddenUnits=128, n_observations=None, n_actions=None, replay_buffer_max_size=5000, batch_size=32, target_net_update=100, tau=0.005)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = Params(\n",
    "    # seed=42,\n",
    "    # seed=123,\n",
    "    n_runs=1,\n",
    "    total_episodes=60,\n",
    "    epsilon=0.5,\n",
    "    alpha=1e-4,\n",
    "    gamma=0.99,\n",
    "    # nHiddenUnits=(5 * 5 + 3) * 5,\n",
    "    nHiddenUnits=128,\n",
    "    replay_buffer_max_size=5000,\n",
    "    epsilon_min=0.2,\n",
    "    epsilon_max=1.0,\n",
    "    decay_rate=0.01,\n",
    "    epsilon_warmup=100,\n",
    "    batch_size=32,\n",
    "    # target_net_update=200,\n",
    "    tau=0.005,\n",
    ")\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if p.batch_size < 2:\n",
    "    raise ValueError(\"The batch size needs to be more that one data point\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "NP28hCqLiVSy"
   },
   "outputs": [],
   "source": [
    "# Set the seed\n",
    "GENERATOR = make_deterministic(seed=p.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0fz-X3HTQueX"
   },
   "source": [
    "### Environment definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the environment\n",
    "env = WrappedEnvironment(one_hot_state=True, seed=p.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of actions: 4\n",
      "Number of observations: 28\n"
     ]
    }
   ],
   "source": [
    "# Get number of actions\n",
    "# n_actions = env.action_space.n\n",
    "p.n_actions = env.numActions\n",
    "\n",
    "# Get the number of state observations\n",
    "# state, info = env.reset()\n",
    "state = env.reset()\n",
    "p.n_observations = len(state)\n",
    "\n",
    "print(f\"Number of actions: {p.n_actions}\")\n",
    "print(f\"Number of observations: {p.n_observations}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ENCODER_NEURONS_NUM = 5\n",
    "\n",
    "\n",
    "class DQN(nn.Module):\n",
    "    def __init__(self, n_observations, n_actions, n_units=16):\n",
    "        super(DQN, self).__init__()\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(n_observations, n_units),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(n_units, n_units),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(n_units, ENCODER_NEURONS_NUM),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(ENCODER_NEURONS_NUM, n_units),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(n_units, n_units),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(n_units, n_actions),\n",
    "            # nn.ReLU(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.mlp(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def neural_network():\n",
    "    # if env.one_hot_state:\n",
    "    #     net = DQN(\n",
    "    #         n_observations=p.n_observations,\n",
    "    #         n_actions=p.n_actions,\n",
    "    #         n_units=4 * p.n_observations,\n",
    "    #     ).to(DEVICE)\n",
    "    # else:\n",
    "    #     net = DQN(\n",
    "    #         n_observations=p.n_observations,\n",
    "    #         n_actions=p.n_actions,\n",
    "    #         n_units=p.nHiddenUnits,\n",
    "    #     ).to(DEVICE)\n",
    "    # net\n",
    "\n",
    "    net = DQN(\n",
    "        n_observations=p.n_observations,\n",
    "        n_actions=p.n_actions,\n",
    "        n_units=p.nHiddenUnits,\n",
    "    ).to(DEVICE)\n",
    "\n",
    "    target_net = DQN(\n",
    "        n_observations=p.n_observations,\n",
    "        n_actions=p.n_actions,\n",
    "        n_units=p.nHiddenUnits,\n",
    "    ).to(DEVICE)\n",
    "\n",
    "    target_net.load_state_dict(net.state_dict())\n",
    "\n",
    "    return net, target_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(DQN(\n",
       "   (mlp): Sequential(\n",
       "     (0): Linear(in_features=28, out_features=128, bias=True)\n",
       "     (1): ReLU()\n",
       "     (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "     (3): ReLU()\n",
       "     (4): Linear(in_features=128, out_features=5, bias=True)\n",
       "     (5): ReLU()\n",
       "     (6): Linear(in_features=5, out_features=128, bias=True)\n",
       "     (7): ReLU()\n",
       "     (8): Linear(in_features=128, out_features=128, bias=True)\n",
       "     (9): ReLU()\n",
       "     (10): Linear(in_features=128, out_features=4, bias=True)\n",
       "   )\n",
       " ),\n",
       " DQN(\n",
       "   (mlp): Sequential(\n",
       "     (0): Linear(in_features=28, out_features=128, bias=True)\n",
       "     (1): ReLU()\n",
       "     (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "     (3): ReLU()\n",
       "     (4): Linear(in_features=128, out_features=5, bias=True)\n",
       "     (5): ReLU()\n",
       "     (6): Linear(in_features=5, out_features=128, bias=True)\n",
       "     (7): ReLU()\n",
       "     (8): Linear(in_features=128, out_features=128, bias=True)\n",
       "     (9): ReLU()\n",
       "     (10): Linear(in_features=128, out_features=4, bias=True)\n",
       "   )\n",
       " ))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net, target_net = neural_network()\n",
    "net, target_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_untrained = [layer.detach() for layer in net.parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Parameters sizes summary:\n",
      "[torch.Size([128, 28]), torch.Size([128]), torch.Size([128, 128]), torch.Size([128]), torch.Size([5, 128]), torch.Size([5]), torch.Size([128, 5]), torch.Size([128]), torch.Size([128, 128]), torch.Size([128]), torch.Size([4, 128]), torch.Size([4])]\n"
     ]
    }
   ],
   "source": [
    "# print(\"Model parameters:\")\n",
    "# print(list(net.parameters()))\n",
    "print(\"\\n\\nParameters sizes summary:\")\n",
    "print([item.shape for item in net.parameters()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary(net, input_size=[state.shape], verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdamW (\n",
       "Parameter Group 0\n",
       "    amsgrad: True\n",
       "    betas: (0.9, 0.999)\n",
       "    capturable: False\n",
       "    differentiable: False\n",
       "    eps: 1e-08\n",
       "    foreach: None\n",
       "    fused: None\n",
       "    lr: 0.0001\n",
       "    maximize: False\n",
       "    weight_decay: 0.01\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = optim.AdamW(net.parameters(), lr=p.alpha, amsgrad=True)\n",
    "optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "explorer = EpsilonGreedy(\n",
    "    epsilon=p.epsilon_max,\n",
    "    epsilon_min=p.epsilon_min,\n",
    "    epsilon_max=p.epsilon_max,\n",
    "    decay_rate=p.decay_rate,\n",
    "    epsilon_warmup=p.epsilon_warmup,\n",
    "    seed=p.seed,\n",
    ")\n",
    "episodes = torch.arange(p.total_episodes, device=DEVICE)\n",
    "epsilons = torch.empty_like(episodes, device=DEVICE) * torch.nan\n",
    "for eps_i, epsi in enumerate(epsilons):\n",
    "    epsilons[eps_i] = explorer.epsilon\n",
    "    explorer.epsilon = explorer.update_epsilon(episodes[eps_i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "sns.lineplot(epsilons.cpu())\n",
    "ax.set(ylabel=\"Epsilon\")\n",
    "ax.set(xlabel=\"Episodes\")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_weights_biases(net):\n",
    "    biases = {\"val\": [], \"grad\": []}\n",
    "    weights = {\"val\": [], \"grad\": []}\n",
    "    for layer in net.mlp.children():\n",
    "        layer_params = layer.parameters()\n",
    "        for idx, subparams in enumerate(layer_params):\n",
    "            if idx > 2:\n",
    "                raise ValueError(\n",
    "                    \"There should be max 2 sets of parameters: weights and biases\"\n",
    "                )\n",
    "            if len(subparams.shape) > 2:\n",
    "                raise ValueError(\"The weights have more dimensions than expected\")\n",
    "\n",
    "            if len(subparams.shape) == 1:\n",
    "                biases[\"val\"].append(subparams)\n",
    "                biases[\"grad\"].append(subparams.grad)\n",
    "            elif len(subparams.shape) == 2:\n",
    "                weights[\"val\"].append(subparams)\n",
    "                weights[\"grad\"].append(subparams.grad)\n",
    "    return weights, biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def params_df_stats(weights, key, current_df=None):\n",
    "    if current_df is not None:\n",
    "        last_idx = current_df.index[-1] + 1\n",
    "        df = current_df\n",
    "    else:\n",
    "        last_idx = 0\n",
    "        df = None\n",
    "\n",
    "    for idx, val in enumerate(weights[key]):\n",
    "        tmp_df = pd.DataFrame(\n",
    "            data={\n",
    "                \"Std\": val.detach().cpu().std().item(),\n",
    "                \"Avg\": val.detach().cpu().mean().item(),\n",
    "                \"Layer\": idx,\n",
    "                \"Index\": [last_idx + idx],\n",
    "            },\n",
    "            index=[last_idx + idx],\n",
    "        )\n",
    "\n",
    "        if df is None:\n",
    "            df = tmp_df\n",
    "        else:\n",
    "            df = pd.concat((df, tmp_df))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "Transition = namedtuple(\n",
    "    \"Transition\", (\"state\", \"action\", \"reward\", \"next_state\", \"done\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uyEdi0gGiV1z",
    "outputId": "b644224d-13ff-4806-d751-0088efc24f85",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                      \r"
     ]
    }
   ],
   "source": [
    "rewards = torch.zeros((p.total_episodes, p.n_runs), device=DEVICE)\n",
    "steps = torch.zeros((p.total_episodes, p.n_runs), device=DEVICE)\n",
    "episodes = torch.arange(p.total_episodes, device=DEVICE)\n",
    "# all_states = []\n",
    "all_actions = []\n",
    "losses = [[] for _ in range(p.n_runs)]\n",
    "\n",
    "for run in range(p.n_runs):  # Run several times to account for stochasticity\n",
    "    # Reset everything\n",
    "    net, target_net = neural_network()  # Reset weights\n",
    "    optimizer = optim.AdamW(net.parameters(), lr=p.alpha, amsgrad=True)\n",
    "    explorer = EpsilonGreedy(\n",
    "        epsilon=p.epsilon_max,\n",
    "        epsilon_min=p.epsilon_min,\n",
    "        epsilon_max=p.epsilon_max,\n",
    "        decay_rate=p.decay_rate,\n",
    "        epsilon_warmup=p.epsilon_warmup,\n",
    "    )\n",
    "    weights_val_stats = None\n",
    "    biases_val_stats = None\n",
    "    weights_grad_stats = None\n",
    "    biases_grad_stats = None\n",
    "    replay_buffer = deque([], maxlen=p.replay_buffer_max_size)\n",
    "    epsilons = []\n",
    "\n",
    "    for episode in tqdm(\n",
    "        episodes, desc=f\"Run {run+1}/{p.n_runs} - Episodes\", leave=False\n",
    "    ):\n",
    "        state = env.reset()  # Reset the environment\n",
    "        state = state.clone().float().detach().to(DEVICE)\n",
    "        step_count = 0\n",
    "        done = False\n",
    "        total_rewards = 0\n",
    "        loss = torch.ones(1, device=DEVICE) * torch.nan\n",
    "\n",
    "        while not done:\n",
    "            state_action_values = net(state).to(DEVICE)  # Q(s_t)\n",
    "            action = explorer.choose_action(\n",
    "                action_space=env.action_space,\n",
    "                state=state,\n",
    "                state_action_values=state_action_values,\n",
    "            ).item()\n",
    "\n",
    "            # Record states and actions\n",
    "            # all_states.append(state)\n",
    "            # all_actions.append(Actions(action.item()).name)\n",
    "            all_actions.append(Actions(action).name)\n",
    "\n",
    "            next_state, reward, done = env.step(action=action, current_state=state)\n",
    "\n",
    "            # Store transition in replay buffer\n",
    "            # [current_state (2 or 28 x1), action (1x1), next_state (2 or 28 x1), reward (1x1), done (1x1 bool)]\n",
    "            done = torch.tensor(done, device=DEVICE).unsqueeze(-1)\n",
    "            replay_buffer.append(\n",
    "                Transition(\n",
    "                    state,\n",
    "                    action,\n",
    "                    reward,\n",
    "                    next_state,\n",
    "                    done,\n",
    "                )\n",
    "            )\n",
    "\n",
    "            # Start training when `replay_buffer` is full\n",
    "            if len(replay_buffer) == p.replay_buffer_max_size:\n",
    "                transitions = random_choice(\n",
    "                    replay_buffer,\n",
    "                    length=len(replay_buffer),\n",
    "                    num_samples=p.batch_size,\n",
    "                    generator=GENERATOR,\n",
    "                )\n",
    "                batch = Transition(*zip(*transitions, strict=True))\n",
    "                state_batch = torch.stack(batch.state)\n",
    "                action_batch = torch.tensor(batch.action, device=DEVICE)\n",
    "                reward_batch = torch.cat(batch.reward)\n",
    "                next_state_batch = torch.stack(batch.next_state)\n",
    "                done_batch = torch.cat(batch.done)\n",
    "\n",
    "                # See DQN paper for equations: https://doi.org/10.1038/nature14236\n",
    "                state_action_values_sampled = net(state_batch).to(DEVICE)  # Q(s_t)\n",
    "                state_action_values = torch.gather(\n",
    "                    input=state_action_values_sampled,\n",
    "                    dim=1,\n",
    "                    index=action_batch.unsqueeze(-1),\n",
    "                ).squeeze()  # Q(s_t, a)\n",
    "\n",
    "                # done_false = torch.argwhere(done_batch == False).squeeze()\n",
    "                # done_true = torch.argwhere(done_batch == True).squeeze()\n",
    "                # expected_state_action_values = (\n",
    "                #     torch.zeros_like(done_batch, device=DEVICE)\n",
    "                # ).float()\n",
    "                # with torch.no_grad():\n",
    "                #     if done_true.numel() > 0:\n",
    "                #         expected_state_action_values[done_true] = reward_batch[\n",
    "                #             done_true\n",
    "                #         ]\n",
    "                #     if done_false.numel() > 0:\n",
    "                #         next_state_values = (\n",
    "                #             target_net(next_state_batch[done_false]).to(DEVICE).max(1)\n",
    "                #         )  # Q(s_t+1, a)\n",
    "                #         expected_state_action_values[done_false] = (\n",
    "                #             reward_batch[done_false]\n",
    "                #             + p.gamma * next_state_values.values\n",
    "                #         )  # y_j (Bellman optimality equation)\n",
    "\n",
    "                # Compute a mask of non-final states and concatenate the batch elements\n",
    "                # (a final state would've been the one after which simulation ended)\n",
    "                non_final_mask = torch.tensor(\n",
    "                    tuple(map(lambda s: s == False, batch.done)),\n",
    "                    device=DEVICE,\n",
    "                    dtype=torch.bool,\n",
    "                )\n",
    "                non_final_next_states = torch.stack(\n",
    "                    [s[1] for s in zip(batch.done, batch.next_state) if s[0] == False]\n",
    "                )\n",
    "\n",
    "                # Compute V(s_{t+1}) for all next states.\n",
    "                # Expected values of actions for non_final_next_states are computed based\n",
    "                # on the \"older\" target_net; selecting their best reward with max(1).values\n",
    "                # This is merged based on the mask, such that we'll have either the expected\n",
    "                # state value or 0 in case the state was final.\n",
    "                next_state_values = torch.zeros(p.batch_size, device=DEVICE)\n",
    "                if non_final_next_states.numel() > 0 and non_final_mask.numel() > 0:\n",
    "                    with torch.no_grad():\n",
    "                        next_state_values[non_final_mask] = (\n",
    "                            target_net(non_final_next_states).max(1).values\n",
    "                        )\n",
    "                # Compute the expected Q values\n",
    "                expected_state_action_values = reward_batch + (\n",
    "                    next_state_values * p.gamma\n",
    "                )\n",
    "\n",
    "                # Compute loss\n",
    "                # criterion = nn.MSELoss()\n",
    "                criterion = nn.SmoothL1Loss()\n",
    "                loss = criterion(\n",
    "                    input=state_action_values,  # prediction\n",
    "                    target=expected_state_action_values,  # target/\"truth\" value\n",
    "                )  # TD update\n",
    "\n",
    "                # Optimize the model\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_value_(\n",
    "                    net.parameters(), 100\n",
    "                )  # In-place gradient clipping\n",
    "                optimizer.step()\n",
    "\n",
    "                # # Reset the target network\n",
    "                # if step_count % p.target_net_update == 0:\n",
    "                #     target_net.load_state_dict(net.state_dict())\n",
    "\n",
    "                # Soft update of the target network's weights\n",
    "                # θ′ ← τ θ + (1 −τ )θ′\n",
    "                target_net_state_dict = target_net.state_dict()\n",
    "                net_state_dict = net.state_dict()\n",
    "                for key in net_state_dict:\n",
    "                    target_net_state_dict[key] = net_state_dict[\n",
    "                        key\n",
    "                    ] * p.tau + target_net_state_dict[key] * (1 - p.tau)\n",
    "                target_net.load_state_dict(target_net_state_dict)\n",
    "\n",
    "                losses[run].append(loss.item())\n",
    "\n",
    "                weights, biases = collect_weights_biases(net=net)\n",
    "                weights_val_stats = params_df_stats(\n",
    "                    weights, key=\"val\", current_df=weights_grad_stats\n",
    "                )\n",
    "                biases_val_stats = params_df_stats(\n",
    "                    biases, key=\"val\", current_df=biases_val_stats\n",
    "                )\n",
    "                biases_grad_stats = params_df_stats(\n",
    "                    biases, key=\"grad\", current_df=biases_grad_stats\n",
    "                )\n",
    "                weights_grad_stats = params_df_stats(\n",
    "                    weights, key=\"grad\", current_df=weights_val_stats\n",
    "                )\n",
    "\n",
    "            total_rewards += reward\n",
    "            step_count += 1\n",
    "\n",
    "            # Move to the next state\n",
    "            state = next_state\n",
    "\n",
    "            explorer.epsilon = explorer.update_epsilon(episode)\n",
    "            epsilons.append(explorer.epsilon)\n",
    "\n",
    "        rewards[episode, run] = total_rewards\n",
    "        steps[episode, run] = step_count\n",
    "        logger.info(\n",
    "            f\"Run: {run+1}/{p.n_runs} - Episode: {episode+1}/{p.total_episodes} - Steps: {step_count} - Loss: {loss.item()}\"\n",
    "        )\n",
    "    weights_val_stats.set_index(\"Index\", inplace=True)\n",
    "    biases_val_stats.set_index(\"Index\", inplace=True)\n",
    "    biases_grad_stats.set_index(\"Index\", inplace=True)\n",
    "    weights_grad_stats.set_index(\"Index\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save data to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = CURRENT_PATH / \"data.npz\"\n",
    "with open(data_path, \"wb\") as fhd:\n",
    "    np.savez(\n",
    "        fhd,\n",
    "        rewards=rewards.cpu(),\n",
    "        steps=steps.cpu(),\n",
    "        episodes=episodes.cpu(),\n",
    "        all_actions=all_actions,\n",
    "        losses=losses,\n",
    "        p=p,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_path = CURRENT_PATH / \"data.pkl\"\n",
    "# with open(data_path, \"wb\") as fhd:\n",
    "#     pickle.dump(\n",
    "#         [\n",
    "#             rewards,\n",
    "#             steps,\n",
    "#             episodes,\n",
    "#             all_actions,\n",
    "#             losses,\n",
    "#             p,\n",
    "#         ],\n",
    "#         fhd,\n",
    "#     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uyEdi0gGiV1z",
    "outputId": "b644224d-13ff-4806-d751-0088efc24f85",
    "tags": []
   },
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data from disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_path, \"rb\") as fhd:\n",
    "    # Load the arrays from the .npz file\n",
    "    data = np.load(fhd, allow_pickle=True)\n",
    "\n",
    "    # Access individual arrays by their names\n",
    "    rewards = data[\"rewards\"]\n",
    "    steps = data[\"steps\"]\n",
    "    episodes = data[\"episodes\"]\n",
    "    all_actions = data[\"all_actions\"]\n",
    "    losses = data[\"losses\"]\n",
    "    p = data[\"p\"][()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(data_path, \"rb\") as fhd:\n",
    "#     obj = pickle.load(fhd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obj[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploration rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_exploration_rate(epsilons, figpath=None):\n",
    "    fig, ax = plt.subplots()\n",
    "    sns.lineplot(epsilons)\n",
    "    ax.set(ylabel=\"Epsilon\")\n",
    "    ax.set(xlabel=\"Steps\")\n",
    "    fig.tight_layout()\n",
    "    fig.patch.set_alpha(0)\n",
    "    fig.patch.set_facecolor(\"white\")\n",
    "    if figpath:\n",
    "        fig.savefig(figpath / \"exploration-rate.png\", bbox_inches=\"tight\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_exploration_rate(epsilons, figpath=CURRENT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### States & actions distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocess(episodes, p, rewards, steps):\n",
    "    \"\"\"Convert the results of the simulation in dataframes.\"\"\"\n",
    "    res = pd.DataFrame(\n",
    "        data={\n",
    "            \"Episodes\": episodes.tile(p.n_runs).cpu(),\n",
    "            \"Rewards\": rewards.T.flatten().cpu(),\n",
    "            \"Steps\": steps.T.flatten().cpu(),\n",
    "        }\n",
    "    )\n",
    "    # res[\"cum_rewards\"] = rewards.cumsum(axis=0).flatten(order=\"F\")\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'tile'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mpostprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepisodes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrewards\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msteps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m res\n",
      "Cell \u001b[0;32mIn[35], line 5\u001b[0m, in \u001b[0;36mpostprocess\u001b[0;34m(episodes, p, rewards, steps)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpostprocess\u001b[39m(episodes, p, rewards, steps):\n\u001b[1;32m      2\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Convert the results of the simulation in dataframes.\"\"\"\u001b[39;00m\n\u001b[1;32m      3\u001b[0m     res \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(\n\u001b[1;32m      4\u001b[0m         data\u001b[38;5;241m=\u001b[39m{\n\u001b[0;32m----> 5\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpisodes\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[43mepisodes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtile\u001b[49m(p\u001b[38;5;241m.\u001b[39mn_runs)\u001b[38;5;241m.\u001b[39mcpu(),\n\u001b[1;32m      6\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRewards\u001b[39m\u001b[38;5;124m\"\u001b[39m: rewards\u001b[38;5;241m.\u001b[39mT\u001b[38;5;241m.\u001b[39mflatten()\u001b[38;5;241m.\u001b[39mcpu(),\n\u001b[1;32m      7\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSteps\u001b[39m\u001b[38;5;124m\"\u001b[39m: steps\u001b[38;5;241m.\u001b[39mT\u001b[38;5;241m.\u001b[39mflatten()\u001b[38;5;241m.\u001b[39mcpu(),\n\u001b[1;32m      8\u001b[0m         }\n\u001b[1;32m      9\u001b[0m     )\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;66;03m# res[\"cum_rewards\"] = rewards.cumsum(axis=0).flatten(order=\"F\")\u001b[39;00m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'tile'"
     ]
    }
   ],
   "source": [
    "res = postprocess(episodes, p, rewards, steps)\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a sanity check, we will plot the distributions of states and actions\n",
    "with the following function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_actions_distribution(actions, figpath=None):\n",
    "    \"\"\"Plot the distributions of states and actions.\"\"\"\n",
    "    fig, ax = plt.subplots()\n",
    "    sns.histplot(data=actions, ax=ax)\n",
    "    ax.set_xticks(\n",
    "        [item.value for item in Actions], labels=[item.name for item in Actions]\n",
    "    )\n",
    "    ax.set_title(\"Actions\")\n",
    "    fig.tight_layout()\n",
    "    fig.patch.set_alpha(0)\n",
    "    fig.patch.set_facecolor(\"white\")\n",
    "    if figpath:\n",
    "        fig.savefig(figpath / \"actions-distribution.png\", bbox_inches=\"tight\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_actions_distribution(all_actions, figpath=CURRENT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steps & rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 317
    },
    "id": "pk8lHOjiL7fa",
    "outputId": "0474335e-bf29-4be1-d877-e6adc5a13afc"
   },
   "outputs": [],
   "source": [
    "def plot_steps_and_rewards(df, figpath=None):\n",
    "    \"\"\"Plot the steps and rewards from dataframes.\"\"\"\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(15, 5))\n",
    "    sns.lineplot(data=df, x=\"Episodes\", y=\"Rewards\", ax=ax[0])\n",
    "    ax[0].set(\n",
    "        ylabel=f\"Rewards\\naveraged over {p.n_runs} runs\" if p.n_runs > 1 else \"Rewards\"\n",
    "    )\n",
    "\n",
    "    sns.lineplot(data=df, x=\"Episodes\", y=\"Steps\", ax=ax[1])\n",
    "    ax[1].set(\n",
    "        ylabel=(\n",
    "            f\"Steps number\\naveraged over {p.n_runs} runs\"\n",
    "            if p.n_runs > 1\n",
    "            else \"Steps number\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "    fig.tight_layout()\n",
    "    fig.patch.set_alpha(0)\n",
    "    fig.patch.set_facecolor(\"white\")\n",
    "    if figpath:\n",
    "        fig.savefig(figpath / \"steps-and-rewards.png\", bbox_inches=\"tight\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xj1z5ob10ltw"
   },
   "outputs": [],
   "source": [
    "plot_steps_and_rewards(res, figpath=CURRENT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_steps_and_rewards_dist(df, figpath=None):\n",
    "    \"\"\"Plot the steps and rewards distributions from dataframes.\"\"\"\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(15, 5))\n",
    "    sns.histplot(data=df, x=\"Rewards\", ax=ax[0])\n",
    "    sns.histplot(data=df, x=\"Steps\", ax=ax[1])\n",
    "    fig.tight_layout()\n",
    "    fig.patch.set_alpha(0)\n",
    "    fig.patch.set_facecolor(\"white\")\n",
    "    if figpath:\n",
    "        fig.savefig(\n",
    "            figpath / \"steps-and-rewards-distrib.png\",\n",
    "            bbox_inches=\"tight\",\n",
    "        )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_steps_and_rewards_dist(res, figpath=CURRENT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 1\n",
    "for idx, loss in enumerate(losses):\n",
    "    current_loss = torch.tensor(loss, device=DEVICE)\n",
    "    losses_rolling_avg = nn.functional.avg_pool1d(\n",
    "        current_loss.view(1, 1, -1), kernel_size=window_size\n",
    "    ).squeeze()\n",
    "    tmp_df = pd.DataFrame(\n",
    "        data={\n",
    "            \"Run\": idx * torch.ones(len(losses_rolling_avg), device=DEVICE).int().cpu(),\n",
    "            \"Steps\": torch.arange(0, len(losses_rolling_avg), device=DEVICE).cpu(),\n",
    "            \"Loss\": losses_rolling_avg.cpu(),\n",
    "        }\n",
    "    )\n",
    "    if idx == 0:\n",
    "        loss_df = tmp_df\n",
    "    else:\n",
    "        loss_df = pd.concat((loss_df, tmp_df))\n",
    "loss_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "sns.lineplot(data=loss_df, x=\"Steps\", y=\"Loss\", ax=ax)\n",
    "if USETEX:\n",
    "    ax.set(\n",
    "        ylabel=(\n",
    "            f\"$Log_{{10}}(\\mathrm{{Loss}})$\\naveraged over {p.n_runs} runs\"\n",
    "            if p.n_runs > 1\n",
    "            else \"$Log_{10}(\\mathrm{Loss})$\"\n",
    "        )\n",
    "    )\n",
    "else:\n",
    "    ax.set(\n",
    "        ylabel=(\n",
    "            f\"$Log_{{10}}(\\\\text{{Loss}})$\\naveraged over {p.n_runs} runs\"\n",
    "            if p.n_runs > 1\n",
    "            else \"$Log_{10}(\\\\text{Loss})$\"\n",
    "        )\n",
    "    )\n",
    "ax.set(xlabel=\"Steps\")\n",
    "ax.set(yscale=\"log\")\n",
    "fig.tight_layout()\n",
    "fig.patch.set_alpha(0)\n",
    "fig.patch.set_facecolor(\"white\")\n",
    "fig.savefig(CURRENT_PATH / \"loss.png\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Policy learned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    q_values = torch.nan * torch.empty(\n",
    "        (len(env.tiles_locations), len(Cues), p.n_actions), device=DEVICE\n",
    "    )\n",
    "    for tile_i, tile_v in enumerate(env.tiles_locations):\n",
    "        for cue_i, cue_v in enumerate(Cues):\n",
    "            state = torch.tensor([tile_v, cue_v.value], device=DEVICE).float()\n",
    "            if env.one_hot_state:\n",
    "                state = env.to_one_hot(state).float()\n",
    "            q_values[tile_i, cue_i, :] = net(state).to(DEVICE)\n",
    "q_values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with torch.no_grad():\n",
    "#     q_values = torch.nan * torch.empty(\n",
    "#         (len(env.tiles_locations), len(OdorCues), len(LightCues), p.n_actions),\n",
    "#         device=DEVICE,\n",
    "#     )\n",
    "#     for tile_i, tile_v in enumerate(env.tiles_locations):\n",
    "#         for o_cue_i, o_cue_v in enumerate(OdorCues):\n",
    "#             for l_cue_i, l_cue_v in enumerate(LightCues):\n",
    "#                 state = torch.tensor(\n",
    "#                     [tile_v, o_cue_v.value, l_cue_v.value], device=DEVICE\n",
    "#                 ).float()\n",
    "#                 if env.one_hot_state:\n",
    "#                     state = env.to_one_hot(state).float()\n",
    "#                 q_values[tile_i, cue_i, :] = net(state).to(DEVICE)\n",
    "# q_values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def qtable_directions_map(qtable, rows, cols):\n",
    "    \"\"\"Get the best learned action & map it to arrows.\"\"\"\n",
    "    qtable_val_max = qtable.max(axis=1).values.reshape(rows, cols)\n",
    "    qtable_best_action = qtable.argmax(axis=1).reshape(rows, cols)\n",
    "    directions = {\n",
    "        Actions.UP: \"↑\",\n",
    "        Actions.DOWN: \"↓\",\n",
    "        Actions.LEFT: \"←\",\n",
    "        Actions.RIGHT: \"→\",\n",
    "    }\n",
    "    qtable_directions = np.empty(qtable_best_action.flatten().shape, dtype=str)\n",
    "    eps = torch.finfo(torch.float64).eps  # Minimum float number on the machine\n",
    "    for idx, val in enumerate(qtable_best_action.flatten()):\n",
    "        if qtable_val_max.flatten()[idx] > eps:\n",
    "            # Assign an arrow only if a minimal Q-value has been learned as best action\n",
    "            # otherwise since 0 is a direction, it also gets mapped on the tiles where\n",
    "            # it didn't actually learn anything\n",
    "            qtable_directions[idx] = directions[Actions(val.item())]\n",
    "    qtable_directions = qtable_directions.reshape(rows, cols)\n",
    "    return qtable_val_max, qtable_directions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_policies(q_values, labels, figpath=None):\n",
    "    \"\"\"\n",
    "    Plot the heatmap of the Q-values.\n",
    "\n",
    "    Also plot the best action's direction with arrows.\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(2, len(labels), figsize=(13, 8))\n",
    "    for tri_i, tri_v in enumerate(TriangleState):\n",
    "        for cue_i, cue_v in enumerate(labels):\n",
    "            qtable_val_max, qtable_directions = qtable_directions_map(\n",
    "                qtable=q_values[:, cue_i, :], rows=env.rows, cols=env.cols\n",
    "            )\n",
    "            if tri_v == TriangleState.upper:\n",
    "                qtable_val_max = torch.triu(qtable_val_max)\n",
    "                qtable_directions = np.triu(qtable_directions)\n",
    "            elif tri_v == TriangleState.lower:\n",
    "                qtable_val_max = torch.tril(qtable_val_max)\n",
    "                qtable_directions = np.tril(qtable_directions)\n",
    "            sns.heatmap(\n",
    "                qtable_val_max.cpu(),\n",
    "                annot=qtable_directions,\n",
    "                fmt=\"\",\n",
    "                ax=ax[tri_i, cue_i],\n",
    "                cmap=sns.color_palette(\"Blues\", as_cmap=True),\n",
    "                linewidths=0.7,\n",
    "                linecolor=\"black\",\n",
    "                xticklabels=[],\n",
    "                yticklabels=[],\n",
    "                annot_kws={\"fontsize\": \"xx-large\"},\n",
    "                cbar_kws={\"label\": \"Q-value\"},\n",
    "            ).set(title=labels[cue_v])\n",
    "            for _, spine in ax[tri_i, cue_i].spines.items():\n",
    "                spine.set_visible(True)\n",
    "                spine.set_linewidth(0.7)\n",
    "                spine.set_color(\"black\")\n",
    "\n",
    "            # Annotate the ports names\n",
    "            bbox = {\n",
    "                \"facecolor\": \"black\",\n",
    "                \"edgecolor\": \"none\",\n",
    "                \"boxstyle\": \"round\",\n",
    "                \"alpha\": 0.1,\n",
    "            }\n",
    "            ax[tri_i, cue_i].text(\n",
    "                x=4.7,\n",
    "                y=0.3,\n",
    "                s=\"N\",\n",
    "                bbox=bbox,\n",
    "                color=\"white\",\n",
    "            )\n",
    "            ax[tri_i, cue_i].text(\n",
    "                x=0.05,\n",
    "                y=4.9,\n",
    "                s=\"S\",\n",
    "                bbox=bbox,\n",
    "                color=\"white\",\n",
    "            )\n",
    "            ax[tri_i, cue_i].text(\n",
    "                x=4.7,\n",
    "                y=4.9,\n",
    "                s=\"E\",\n",
    "                bbox=bbox,\n",
    "                color=\"white\",\n",
    "            )\n",
    "            ax[tri_i, cue_i].text(\n",
    "                x=0.05,\n",
    "                y=0.3,\n",
    "                s=\"W\",\n",
    "                bbox=bbox,\n",
    "                color=\"white\",\n",
    "            )\n",
    "\n",
    "    # Make background transparent\n",
    "    fig.patch.set_alpha(0)\n",
    "    fig.patch.set_facecolor(\"white\")\n",
    "    fig.tight_layout()\n",
    "    if figpath:\n",
    "        fig.savefig(figpath / \"policy.png\", bbox_inches=\"tight\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_policies(q_values=q_values, labels=CONTEXTS_LABELS, figpath=CURRENT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weights matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_weights_matrices(weights_untrained, weights_trained, figpath=None):\n",
    "    fig = plt.figure(layout=\"constrained\", figsize=(12, 17))\n",
    "    subfigs = fig.subfigures(nrows=1, ncols=2)\n",
    "    ax = []\n",
    "    for subf in subfigs:\n",
    "        ax.append(\n",
    "            subf.subplots(\n",
    "                nrows=round(len(weights_trained) / 2),\n",
    "                ncols=2,\n",
    "                width_ratios=[10, 1],\n",
    "            )\n",
    "        )\n",
    "    subfigs[0].suptitle(\"Before training\")\n",
    "    subfigs[1].suptitle(\"After training\")\n",
    "    # subfigs[0].colorbar(pc, shrink=0.6, ax=axsLeft, location='bottom')\n",
    "    # subfigs[1].colorbar(pc, shrink=0.6, ax=axsRight)\n",
    "    # fig.suptitle('Weights')\n",
    "\n",
    "    for idx, (w_untrained, w_trained) in enumerate(\n",
    "        zip(weights_untrained, weights_trained)\n",
    "    ):\n",
    "        # cmap = \"bwr\"\n",
    "        cmap = \"coolwarm\"\n",
    "\n",
    "        plot_row = int(np.floor(idx / 2))  # Row index to lay out the plots\n",
    "\n",
    "        if len(w_trained.shape) < 2:  # Biases\n",
    "            b_untrained_current = w_untrained.unsqueeze(-1).detach().numpy()\n",
    "            b_trained_current = w_trained.unsqueeze(-1).detach().numpy()\n",
    "            sns.heatmap(b_untrained_current, ax=ax[0][plot_row, 1], cmap=cmap)\n",
    "            sns.heatmap(b_trained_current, ax=ax[1][plot_row, 1], cmap=cmap)\n",
    "            for axi in ax:\n",
    "                axi[plot_row, 1].xaxis.set_major_locator(mpl.ticker.NullLocator())\n",
    "\n",
    "        else:  # Weights\n",
    "            w_untrained_current = w_untrained.detach().numpy()\n",
    "            w_trained_current = w_trained.detach().numpy()\n",
    "            sns.heatmap(w_untrained_current, ax=ax[0][plot_row, 0], cmap=cmap)\n",
    "            sns.heatmap(w_trained_current, ax=ax[1][plot_row, 0], cmap=cmap)\n",
    "            for axi in ax:\n",
    "                axi[plot_row, 0].tick_params(labelbottom=False, labeltop=True)\n",
    "                axi[plot_row, 0].xaxis.set_major_locator(\n",
    "                    mpl.ticker.LinearLocator(numticks=3)\n",
    "                )\n",
    "                for axj in axi.flatten():\n",
    "                    axj.xaxis.set_major_formatter(mpl.ticker.FormatStrFormatter(\"%d\"))\n",
    "\n",
    "    for axlr in ax:\n",
    "        for axi in axlr:\n",
    "            for axj in axi:\n",
    "                axj.yaxis.set_major_locator(mpl.ticker.LinearLocator(numticks=3))\n",
    "                axj.yaxis.set_major_formatter(mpl.ticker.FormatStrFormatter(\"%d\"))\n",
    "\n",
    "        # fig.tight_layout()\n",
    "        fig.patch.set_alpha(0)\n",
    "        fig.patch.set_facecolor(\"white\")\n",
    "    if figpath:\n",
    "        fig.savefig(figpath / \"weights-matrices.png\", bbox_inches=\"tight\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_weights_matrices(\n",
    "    weights_untrained=weights_untrained,\n",
    "    weights_trained=[layer for layer in net.parameters()],\n",
    "    figpath=CURRENT_PATH,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activations learned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[item for item in net.mlp.named_children()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hook to capture the activations\n",
    "activations = {}\n",
    "\n",
    "\n",
    "def get_activation(name):\n",
    "    def hook(module, args, output):\n",
    "        activations[name] = output.detach()\n",
    "\n",
    "    return hook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register the hooks for all layers\n",
    "for name, layer in net.mlp.named_children():\n",
    "    layer.register_forward_hook(get_activation(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(28)\n",
    "output = net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[val.shape for key, val in activations.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct input dictionnary to be fed to the network\n",
    "input_cond = OrderedDict({})\n",
    "for cue_obj, cue_txt in CONTEXTS_LABELS.items():\n",
    "    for loc in env.state_space[\"location\"]:\n",
    "        current_state = torch.tensor([loc, cue_obj.value], device=DEVICE)\n",
    "        if env.one_hot_state:\n",
    "            current_state = env.to_one_hot(current_state)\n",
    "        input_cond[f\"{loc}-{cue_txt}\"] = current_state.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the activations from the network\n",
    "layer_inspected = 6 - 1\n",
    "activations_layer = (\n",
    "    torch.ones((len(input_cond), ENCODER_NEURONS_NUM), device=DEVICE) * torch.nan\n",
    ")\n",
    "for idx, (cond, input_val) in enumerate(input_cond.items()):\n",
    "    net(input_val)\n",
    "    activations_layer[idx, :] = activations[str(layer_inspected)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cols = pd.MultiIndex.from_tuples(\n",
    "#     [(\"neuron\", str(item)) for item in range(1, ENCODER_NEURONS_NUM + 1)]\n",
    "# )\n",
    "activations_layer_df = pd.DataFrame(activations_layer)  # , columns=cols)\n",
    "activations_layer_df[\"Input\"] = list(input_cond.keys())\n",
    "activations_layer_df.set_index(\"Input\", inplace=True)\n",
    "activations_layer_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plot_activations(activations_layer, figpath=None):\n",
    "#     fig, ax = plt.subplots(figsize=(10, 15))\n",
    "#     sns.heatmap(activations_layer, ax=ax)\n",
    "#     ax.set(xlabel=f\"Neurons activations in layer {layer_inspected + 1}\")\n",
    "#     ax.tick_params(top=True, labeltop=True, bottom=False, labelbottom=False)\n",
    "#     ax.xaxis.set_label_position(\"top\")\n",
    "#     ax.set_yticks(np.arange(len(input_cond)) + 0.5)\n",
    "#     ax.set_yticklabels(list(input_cond.keys()), rotation=0)\n",
    "#     fig.tight_layout()\n",
    "#     fig.patch.set_alpha(0)\n",
    "#     fig.patch.set_facecolor(\"white\")\n",
    "#     if figpath:\n",
    "#         fig.savefig(figpath / \"activations-learned.png\", bbox_inches=\"tight\")\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_activations(activations_layer, figpath=CURRENT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_activations(activations_layer, input_cond, labels, figpath=None):\n",
    "    # Create a categorical palette to identify the clusters\n",
    "    # cluster_palette = sns.color_palette(\"Pastel2\")\n",
    "    cluster_palette = sns.color_palette(\"Accent\")\n",
    "    cluster_colors = dict(zip(list(labels.values()), cluster_palette))\n",
    "    row_colors = [cluster_colors[cond.split(\"-\")[1]] for cond in input_cond.keys()]\n",
    "    row_colors_serie = pd.Series(row_colors)\n",
    "    row_colors_serie = row_colors_serie.set_axis(list(input_cond.keys()))\n",
    "\n",
    "    # cmap = \"mako\"\n",
    "    # cmap = \"rocket\"\n",
    "    # cmap = \"magma\"\n",
    "    cmap = \"viridis\"\n",
    "    chart = sns.clustermap(activations_layer_df, cmap=cmap, row_colors=row_colors_serie)\n",
    "    chart.ax_heatmap.set_xlabel(f\"Neurons activations in layer {layer_inspected + 1}\")\n",
    "\n",
    "    for label, col_val in cluster_colors.items():\n",
    "        chart.ax_col_dendrogram.bar(0, 0, color=col_val, label=label, linewidth=0)\n",
    "    chart.ax_col_dendrogram.legend(loc=\"center\", bbox_to_anchor=(1.1, 0.7))  # , ncol=6)\n",
    "\n",
    "    chart.fig.patch.set_alpha(0)\n",
    "    chart.fig.patch.set_facecolor(\"white\")\n",
    "    if figpath:\n",
    "        chart.savefig(figpath / \"activations-learned.png\", bbox_inches=\"tight\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_activations(\n",
    "    activations_layer=activations_layer,\n",
    "    input_cond=input_cond,\n",
    "    labels=CONTEXTS_LABELS,\n",
    "    figpath=CURRENT_PATH,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weights & gradients metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights, biases = collect_weights_biases(net=net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def params_df_flat(weights):\n",
    "    for idx, val in enumerate(weights):\n",
    "        tmp_df = pd.DataFrame(\n",
    "            data={\n",
    "                \"Val\": val.detach().cpu().flatten(),\n",
    "                \"Layer\": idx,\n",
    "            }\n",
    "        )\n",
    "        if idx == 0:\n",
    "            df = tmp_df\n",
    "        else:\n",
    "            df = pd.concat((df, tmp_df))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_val_df = params_df_flat(weights[\"val\"])\n",
    "weights_val_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_val_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "biases_val_df = params_df_flat(biases[\"val\"])\n",
    "biases_val_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "biases_val_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_grad_df = params_df_flat(weights[\"grad\"])\n",
    "weights_grad_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_grad_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "biases_grad_df = params_df_flat(biases[\"grad\"])\n",
    "biases_grad_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "biases_grad_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_grad_stats(grad_df):\n",
    "    grad_stats = torch.tensor(\n",
    "        [\n",
    "            grad_df.Val.mean(),\n",
    "            grad_df.Val.std(),\n",
    "            grad_df.Val.min(),\n",
    "            grad_df.Val.max(),\n",
    "        ],\n",
    "        device=DEVICE,\n",
    "    )\n",
    "    assert not torch.equal(\n",
    "        torch.zeros_like(grad_stats, device=DEVICE),\n",
    "        grad_stats,\n",
    "    ), \"Gradients are zero\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.plot_weights_biases_distributions(\n",
    "    weights_val_df, biases_val_df, label=\"Values\", figpath=CURRENT_PATH\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_grad_stats(weights_grad_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_grad_stats(biases_grad_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.plot_weights_biases_distributions(\n",
    "    weights_grad_df, biases_grad_df, label=\"Gradients\", figpath=CURRENT_PATH\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_val_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "biases_val_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_grad_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "biases_grad_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_weights_biases_stats(weights_stats, biases_stats, label=None, figpath=None):\n",
    "    fig, ax = plt.subplots(nrows=2, ncols=2, figsize=(13, 8))\n",
    "\n",
    "    if label:\n",
    "        ax[0, 0].set_title(\"Weights \" + label)\n",
    "    else:\n",
    "        ax[0, 0].set_title(\"Weights\")\n",
    "    ax[0, 0].set_xlabel(\"Episodes\")\n",
    "    palette = sns.color_palette()[0 : len(weights_stats.Layer.unique())]\n",
    "    sns.lineplot(\n",
    "        data=weights_stats,\n",
    "        x=\"Index\",\n",
    "        y=\"Std\",\n",
    "        hue=\"Layer\",\n",
    "        palette=palette,\n",
    "        ax=ax[0, 0],\n",
    "    )\n",
    "    ax[0, 0].set(yscale=\"log\")\n",
    "\n",
    "    if label:\n",
    "        ax[0, 1].set_title(\"Weights \" + label)\n",
    "    else:\n",
    "        ax[0, 1].set_title(\"Weights\")\n",
    "    ax[0, 1].set_xlabel(\"Episodes\")\n",
    "    palette = sns.color_palette()[0 : len(weights_stats.Layer.unique())]\n",
    "    sns.lineplot(\n",
    "        data=weights_stats,\n",
    "        x=\"Index\",\n",
    "        y=\"Avg\",\n",
    "        hue=\"Layer\",\n",
    "        palette=palette,\n",
    "        ax=ax[0, 1],\n",
    "    )\n",
    "    ax[0, 1].set(yscale=\"log\")\n",
    "\n",
    "    if label:\n",
    "        ax[1, 0].set_title(\"Biases \" + label)\n",
    "    else:\n",
    "        ax[1, 0].set_title(\"Biases\")\n",
    "    ax[1, 0].set_xlabel(\"Steps\")\n",
    "    palette = sns.color_palette()[0 : len(biases_stats.Layer.unique())]\n",
    "    sns.lineplot(\n",
    "        data=biases_stats,\n",
    "        x=\"Index\",\n",
    "        y=\"Std\",\n",
    "        hue=\"Layer\",\n",
    "        palette=palette,\n",
    "        ax=ax[1, 0],\n",
    "    )\n",
    "    ax[1, 0].set(yscale=\"log\")\n",
    "\n",
    "    if label:\n",
    "        ax[1, 1].set_title(\"Biases \" + label)\n",
    "    else:\n",
    "        ax[1, 1].set_title(\"Biases\")\n",
    "    ax[1, 1].set_xlabel(\"Steps\")\n",
    "    palette = sns.color_palette()[0 : len(biases_stats.Layer.unique())]\n",
    "    sns.lineplot(\n",
    "        data=biases_stats,\n",
    "        x=\"Index\",\n",
    "        y=\"Avg\",\n",
    "        hue=\"Layer\",\n",
    "        palette=palette,\n",
    "        ax=ax[1, 1],\n",
    "    )\n",
    "    ax[1, 1].set(yscale=\"log\")\n",
    "\n",
    "    fig.tight_layout()\n",
    "    fig.patch.set_alpha(0)\n",
    "    fig.patch.set_facecolor(\"white\")\n",
    "    if figpath:\n",
    "        fig.savefig(\n",
    "            figpath / f\"weights-biases-stats-{label}.png\",\n",
    "            bbox_inches=\"tight\",\n",
    "        )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_weights_biases_stats(\n",
    "    weights_val_stats, biases_val_stats, label=\"values\", figpath=CURRENT_PATH\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_weights_biases_stats(\n",
    "    weights_grad_stats, biases_grad_stats, label=\"gradients\", figpath=CURRENT_PATH\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weights_val_stats.rolling(10, center=True).mean().dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rolling_win = 100\n",
    "# plot_weights_biases_stats(\n",
    "#     weights_val_stats.rolling(rolling_win, center=True).mean().dropna(),\n",
    "#     biases_val_stats.rolling(rolling_win, center=True).mean().dropna(),\n",
    "#     label=\"values\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rolling_win = 100\n",
    "# plot_weights_biases_stats(\n",
    "#     weights_grad_stats.rolling(rolling_win, center=True).mean().dropna(),\n",
    "#     biases_grad_stats.rolling(rolling_win, center=True).mean().dropna(),\n",
    "#     label=\"values\",\n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
