{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d1a9876-eccf-4a9f-9ab7-871420850917",
   "metadata": {},
   "source": [
    "# Ablation experiment\n",
    "\n",
    "**Goal of the experiment:** silence or randomize one set of coordinates (Cartesian/polar) to see the effects\n",
    "\n",
    "Potential metrics:\n",
    "- performance histogram\n",
    "- % correct\n",
    "- shift in behavior\n",
    "- Steps number"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d9cbf27-5034-4fff-98f8-d09ea788bc81",
   "metadata": {},
   "source": [
    "## Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c36036ed-d545-4741-b3d3-0ad5fe724f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from collections import deque, namedtuple\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# from utils import make_deterministic, random_choice\n",
    "from agent import EpsilonGreedy, neural_network\n",
    "import utils\n",
    "from environment import CONTEXTS_LABELS, Actions, Cues, DuplicatedCoordsEnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94766291-0065-4ce4-9860-eb85065f2fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2abaebf9-c19c-4a2c-9b9b-43494a4c991c",
   "metadata": {},
   "source": [
    "## Experiment params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6accd8c4-d1ed-4774-ba3e-08eada9bca26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep = \"cartesian\"\n",
    "keep = \"polar\"\n",
    "silence = True\n",
    "# silence = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f1dd3e-232d-43ed-b018-766ae287a604",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b1e9cba-9b8f-459d-a4f5-bc68b2cb1c11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_path = Path(\"..\") / \"save\"\n",
    "save_path.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46ac9dbd-d9e5-4622-a470-20e1a5d30766",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data_dir = save_path / \"2025-03-08_01-44-12_EastWest_save-all-agents\"\n",
    "data_dir = save_path / \"2025-03-08_01-47-50_LeftRight_save-all-agents\"\n",
    "data_dir.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "365b8e4a-f152-4b88-a196-4c2b62f7c388",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = data_dir / \"data.tar\"\n",
    "data_path.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b77c9e7f-e51f-49d0-b4bf-5cbd09f65928",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = data_dir / \"trained-agent-state-0.pt\"\n",
    "model_path.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4886e019-754b-4059-b749-f49cc9840595",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = torch.load(data_path, weights_only=False, map_location=DEVICE)\n",
    "\n",
    "# Access individual arrays by their names\n",
    "p = data_dict[\"p\"]\n",
    "env = data_dict[\"env\"]\n",
    "net = data_dict[\"net\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad40683-a750-4804-89f9-4e3db5b4c5a8",
   "metadata": {},
   "source": [
    "## Inference loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cfcf5dd4-336c-4d35-a881-b3ae94dfb113",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ablate_state(state, keep, silence=True):\n",
    "    new_state = state\n",
    "    if keep == \"cartesian\":\n",
    "        idx = torch.arange(start=9, end=19, device=DEVICE)\n",
    "    elif keep == \"polar\":\n",
    "        idx = torch.arange(start=1, end=9, device=DEVICE)\n",
    "    else:\n",
    "        raise ValueError(\"The state to keep can only be either 'polar' or 'cartesian'\")\n",
    "    if silence:\n",
    "        repl_val = 0\n",
    "    else:\n",
    "        if len(state.shape) > 1:\n",
    "            repl_val = torch.rand((state.shape[0], len(idx)), device=DEVICE)\n",
    "        else:\n",
    "            repl_val = torch.rand(len(idx), device=DEVICE)\n",
    "    if len(state.shape) > 1:\n",
    "        new_state[:, idx] = repl_val\n",
    "    else:\n",
    "        new_state[idx] = repl_val\n",
    "    return new_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "50186a54-0dd4-4285-a7d3-8b0ea040fab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# state = env.reset()  # Reset the environment\n",
    "# state = state.clone().float().detach().to(DEVICE)\n",
    "# state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7c11055b-c03b-422f-b406-b7cfdf482014",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ablate_state(state=state, keep=keep, silence=silence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dee54451-edbf-4f5b-af84-80534081fde0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# state_batch = torch.tile(state, (3,1))\n",
    "# state_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8972683b-f885-43b3-978c-5eb42285f884",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ablate_state(state=state_batch, keep=keep, silence=silence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c8fafa37-d491-438d-8076-b7cea16afcc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "episodes = torch.arange(p.total_episodes/4, device=DEVICE)\n",
    "replay_buffer = deque([], maxlen=p.replay_buffer_max_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aec1e4cd-a734-4b5c-8442-3194a78d88f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Transition = namedtuple(\n",
    "    \"Transition\", (\"state\", \"action\", \"reward\", \"next_state\", \"done\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fff8aa39-f4bd-4944-95cf-fc1e1eb14a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "net, _ = neural_network(\n",
    "    n_observations=p.n_observations,\n",
    "    n_actions=p.n_actions,\n",
    "    nHiddenUnits=p.n_hidden_units,\n",
    ")  # Reset weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f17b42f7-466d-4324-ac92-b259f6d2066d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load trained state from data\n",
    "trained_state_dict = torch.load(model_path, weights_only=True, map_location=DEVICE)\n",
    "net.load_state_dict(trained_state_dict)\n",
    "# target_net.load_state_dict(trained_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aaef8e8e-0b8d-4ee4-bf03-31d7d0cbc4ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer = optim.AdamW(net.parameters(), lr=p.alpha, amsgrad=True)\n",
    "explorer = EpsilonGreedy(\n",
    "    epsilon=p.epsilon_max,\n",
    "    epsilon_min=p.epsilon_min,\n",
    "    epsilon_max=p.epsilon_max,\n",
    "    decay_rate=p.decay_rate,\n",
    "    epsilon_warmup=p.epsilon_warmup,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d481527a-ec5c-46dc-b011-ecea3011a2dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explorer.epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f1a9fa-6f3f-47a7-88cf-7c009afbb6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for episode in tqdm(episodes):\n",
    "    state = env.reset()  # Reset the environment\n",
    "    state = state.clone().float().detach().to(DEVICE)\n",
    "    step_count = 0\n",
    "    done = False\n",
    "    total_rewards = 0\n",
    "    loss = torch.ones(1, device=DEVICE) * torch.nan\n",
    "    \n",
    "    while not done:\n",
    "        state_action_values = net(ablate_state(state=state, keep=keep, silence=silence)).to(DEVICE)  # Q(s_t)\n",
    "        action = explorer.choose_action(\n",
    "            action_space=env.action_space,\n",
    "            state=state,\n",
    "            state_action_values=state_action_values,\n",
    "        ).item()\n",
    "    \n",
    "        # # Record states and actions\n",
    "        # all_states[run][episode].append(state.cpu())\n",
    "        # all_actions[run][episode].append(Actions(action).name)\n",
    "    \n",
    "        next_state, reward, done = env.step(action=action, current_state=state)\n",
    "    \n",
    "        # Store transition in replay buffer\n",
    "        # [current_state (2 or 28 x1), action (1x1), next_state (2 or 28 x1),\n",
    "        # reward (1x1), done (1x1 bool)]\n",
    "        done = torch.tensor(done, device=DEVICE).unsqueeze(-1)\n",
    "        replay_buffer.append(\n",
    "            Transition(\n",
    "                state,\n",
    "                action,\n",
    "                reward,\n",
    "                next_state,\n",
    "                done,\n",
    "            )\n",
    "        )\n",
    "    \n",
    "        # # Start training when `replay_buffer` is full\n",
    "        # if len(replay_buffer) == p.replay_buffer_max_size:\n",
    "        #     transitions = utils.random_choice(\n",
    "        #         replay_buffer,\n",
    "        #         length=len(replay_buffer),\n",
    "        #         num_samples=p.batch_size,\n",
    "        #         generator=None,\n",
    "        #     )\n",
    "        #     batch = Transition(*zip(*transitions, strict=True))\n",
    "        #     state_batch = torch.stack(batch.state)\n",
    "        #     action_batch = torch.tensor(batch.action, device=DEVICE)\n",
    "        #     reward_batch = torch.cat(batch.reward)\n",
    "        #     # next_state_batch = torch.stack(batch.next_state)\n",
    "        #     # done_batch = torch.cat(batch.done)\n",
    "    \n",
    "        #     # See DQN paper for equations: https://doi.org/10.1038/nature14236\n",
    "        #     state_action_values_sampled = net(ablate_state(state=state_batch, keep=keep, silence=silence)).to(DEVICE)  # Q(s_t)\n",
    "        #     state_action_values = torch.gather(\n",
    "        #         input=state_action_values_sampled,\n",
    "        #         dim=1,\n",
    "        #         index=action_batch.unsqueeze(-1),\n",
    "        #     ).squeeze()  # Q(s_t, a)\n",
    "    \n",
    "        #     # Compute a mask of non-final states and concatenate\n",
    "        #     # the batch elements\n",
    "        #     # (a final state would've been the one after which simulation ended)\n",
    "        #     non_final_mask = torch.tensor(\n",
    "        #         tuple(map(lambda s: not s, batch.done)),\n",
    "        #         device=DEVICE,\n",
    "        #         dtype=torch.bool,\n",
    "        #     )\n",
    "        #     non_final_next_states = torch.stack(\n",
    "        #         [s[1] for s in zip(batch.done, batch.next_state) if not s[0]]\n",
    "        #     )\n",
    "    \n",
    "        #     # Compute V(s_{t+1}) for all next states.\n",
    "        #     # Expected values of actions for non_final_next_states are computed\n",
    "        #     # based on the \"older\" target_net;\n",
    "        #     # selecting their best reward with max(1).values\n",
    "        #     # This is merged based on the mask,\n",
    "        #     # such that we'll have either the expected\n",
    "        #     # state value or 0 in case the state was final.\n",
    "        #     next_state_values = torch.zeros(p.batch_size, device=DEVICE)\n",
    "        #     if non_final_next_states.numel() > 0 and non_final_mask.numel() > 0:\n",
    "        #         with torch.no_grad():\n",
    "        #             next_state_values[non_final_mask] = (\n",
    "        #                 target_net(ablate_state(state=non_final_next_states, keep=keep, silence=silence)).max(1).values\n",
    "        #             )\n",
    "        #     # Compute the expected Q values\n",
    "        #     expected_state_action_values = reward_batch + (\n",
    "        #         next_state_values * p.gamma\n",
    "        #     )\n",
    "    \n",
    "        #     # Compute loss\n",
    "        #     # criterion = nn.MSELoss()\n",
    "        #     criterion = nn.SmoothL1Loss()\n",
    "        #     loss = criterion(\n",
    "        #         input=state_action_values,  # prediction\n",
    "        #         target=expected_state_action_values,  # target/\"truth\" value\n",
    "        #     )  # TD update\n",
    "    \n",
    "        #     # Optimize the model\n",
    "        #     optimizer.zero_grad()\n",
    "        #     loss.backward()\n",
    "        #     torch.nn.utils.clip_grad_value_(\n",
    "        #         net.parameters(), 100\n",
    "        #     )  # In-place gradient clipping\n",
    "        #     optimizer.step()\n",
    "    \n",
    "        #     # # Reset the target network\n",
    "        #     # if step_count % p.target_net_update == 0:\n",
    "        #     #     target_net.load_state_dict(net.state_dict())\n",
    "    \n",
    "        #     # Soft update of the target network's weights\n",
    "        #     # θ′ ← τ θ + (1 −τ )θ′\n",
    "        #     target_net_state_dict = target_net.state_dict()\n",
    "        #     net_state_dict = net.state_dict()\n",
    "        #     for key in net_state_dict:\n",
    "        #         target_net_state_dict[key] = net_state_dict[\n",
    "        #             key\n",
    "        #         ] * p.tau + target_net_state_dict[key] * (1 - p.tau)\n",
    "        #     target_net.load_state_dict(target_net_state_dict)\n",
    "    \n",
    "        #     # losses[run].append(loss.item())\n",
    "    \n",
    "        #     # weights, biases = utils.collect_weights_biases(net=net)\n",
    "        #     # weights_val_stats = utils.params_df_stats(\n",
    "        #     #     weights, key=\"val\", current_df=weights_grad_stats\n",
    "        #     # )\n",
    "        #     # biases_val_stats = utils.params_df_stats(\n",
    "        #     #     biases, key=\"val\", current_df=biases_val_stats\n",
    "        #     # )\n",
    "        #     # biases_grad_stats = utils.params_df_stats(\n",
    "        #     #     biases, key=\"grad\", current_df=biases_grad_stats\n",
    "        #     # )\n",
    "        #     # weights_grad_stats = utils.params_df_stats(\n",
    "        #     #     weights, key=\"grad\", current_df=weights_val_stats\n",
    "        #     # )\n",
    "    \n",
    "        total_rewards += reward\n",
    "        step_count += 1\n",
    "    \n",
    "        # Move to the next state\n",
    "        state = next_state\n",
    "    \n",
    "        explorer.epsilon = explorer.update_epsilon(episode)\n",
    "    #     epsilons.append(explorer.epsilon)\n",
    "    \n",
    "    # all_states[run][episode].append(state.cpu())\n",
    "    # rewards[episode, run] = total_rewards\n",
    "    # steps[episode, run] = step_count\n",
    "    # logger.info(\n",
    "    #     f\"Run: {run + 1}/{p.n_runs} - Episode: {episode + 1}/{p.total_episodes}\"\n",
    "    #     f\" - Steps: {step_count} - Loss: {loss.item()}\"\n",
    "    #     f\" - epsilon: {explorer.epsilon}\"\n",
    "    # )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e75a2f-1dc3-4f75-a0c1-bd6ecdc32d04",
   "metadata": {},
   "source": [
    "# Debug"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67553222-def2-4ad7-b199-fdd2f351048a",
   "metadata": {},
   "source": [
    "## Initial conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "69585b82-9a91-4c5f-a688-c432e37e38cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explorer.epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d3120711-d1c7-4852-8dcb-4af5cea76f88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0000e+00,  1.0000e+00,  2.0000e+00, -1.0000e+00,  4.3711e-08,\n",
       "         3.0000e+00,  2.0000e+00,  1.0000e+00, -4.3711e-08,  2.2361e+00,\n",
       "         4.4721e-01,  8.9443e-01, -4.4721e-01,  8.9443e-01,  3.6056e+00,\n",
       "         8.3205e-01,  5.5470e-01,  8.3205e-01, -5.5470e-01])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state = env.reset()  # Reset the environment\n",
    "state = state.clone().float().detach().to(DEVICE)\n",
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "bd655b21-1716-477e-a776-33c9c4f1ce82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TriangleState.upper: 1>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.TriangleState"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a5844f7b-3b9e-468e-a45b-c0fd8d1142d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OdorCondition.pre: 1>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.odor_condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "df800454-cc8c-48f7-8ba2-0325b2014e61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Cues.OdorB: 2>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.odor_ID"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c349321b-9c76-497c-9470-61f796170948",
   "metadata": {},
   "source": [
    "## Create tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5cb6e9f0-2e27-47d8-b3d3-69529771ca80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<Cues.NoOdor: 0>, tensor([90.]), tensor([1.]), tensor([0.]))"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_state = env.conv_flat_duplicated_coords_to_dict(state)\n",
    "Cues(dict_state[\"cue\"].item()), dict_state[\"direction\"], dict_state[\"x\"], dict_state[\"y\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b6584b9d-a99e-484f-9100-e5a1b6245a97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([2]), tensor([1]))"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_state[\"x\"] = torch.tensor([2])\n",
    "dict_state[\"y\"] = torch.tensor([1])\n",
    "dict_state[\"x\"], dict_state[\"y\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0bd48d4c-6658-47d3-851f-d3029594472f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0000e+00,  0.0000e+00,  1.0000e+00, -1.0000e+00,  4.3711e-08,\n",
       "         4.0000e+00,  3.0000e+00,  1.0000e+00, -4.3711e-08,  1.0000e+00,\n",
       "        -4.3711e-08,  1.0000e+00,  1.9471e-07,  1.0000e+00,  5.0000e+00,\n",
       "         8.0000e-01,  6.0000e-01,  8.0000e-01, -6.0000e-01])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_state = env.conv_dict_to_flat_duplicated_coords(dict_state)\n",
    "conv_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "70d3314f-bc00-4496-982f-53806b0ea72e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00,\n",
       "        -4.3711e-08,  1.0000e+00,  1.9471e-07,  1.0000e+00,  5.0000e+00,\n",
       "         8.0000e-01,  6.0000e-01,  8.0000e-01, -6.0000e-01])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_ablated = ablate_state(state=conv_state, keep=keep, silence=silence)\n",
    "state_ablated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8e701417-cb7e-4721-95ff-c48cfdb005fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict_state_ablated = env.conv_flat_duplicated_coords_to_dict(state_ablated)\n",
    "# Cues(dict_state_ablated[\"cue\"].item()), dict_state_ablated[\"direction\"], dict_state_ablated[\"x\"], dict_state_ablated[\"y\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "bef4b35e-5b0a-4795-a604-b45a31ff3a5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.4217, 0.4233, 0.3994], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_action_values = net(state_ablated).to(DEVICE)  # Q(s_t)\n",
    "state_action_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "fc01ff46-b876-4e5f-bcd6-17f5a342be5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Actions.left: 1>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Actions(state_action_values.argmax().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c9b7def2-210e-4461-9e01-884011e2e798",
   "metadata": {},
   "outputs": [],
   "source": [
    "# action = explorer.choose_action(\n",
    "#     action_space=env.action_space,\n",
    "#     state=state,\n",
    "#     state_action_values=state_action_values,\n",
    "# ).item()\n",
    "# action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a93ea76e-dbb2-44a3-8b54-33e0b2a61fa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0.0000e+00,  1.0000e+00,  0.0000e+00,  1.0000e+00, -1.1925e-08,\n",
       "          3.0000e+00,  4.0000e+00, -1.0000e+00,  1.1925e-08,  1.0000e+00,\n",
       "          1.0000e+00,  0.0000e+00,  1.0000e+00, -1.1925e-08,  5.0000e+00,\n",
       "          6.0000e-01,  8.0000e-01, -6.0000e-01,  8.0000e-01]),\n",
       " tensor([0.]),\n",
       " False)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_state, reward, done = env.step(action=action, current_state=state)\n",
    "next_state, reward, done "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "02beb236-8937-43d4-b96c-8e7d75c1fd5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<Cues.NoOdor: 0>, tensor([270.]), tensor([1.]), tensor([2.]))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_next_state = env.conv_flat_duplicated_coords_to_dict(next_state)\n",
    "Cues(dict_next_state[\"cue\"].item()), dict_next_state[\"direction\"], dict_next_state[\"x\"], dict_next_state[\"y\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb69fb7-4e86-421d-9337-69c8c7a3967b",
   "metadata": {},
   "outputs": [],
   "source": [
    "next_state = ablate_state(state=next_state, keep=keep, silence=silence)\n",
    "next_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff8183f-f891-4911-b367-16d32c5df5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move to the next state\n",
    "state = next_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ccf63d-0891-453b-a0a8-425f87245d7f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
