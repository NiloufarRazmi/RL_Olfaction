#+TITLE: Learning useful representations to solve a place-odor association task
# #+SUBTITLE: NSGP seminar
# #+SUBTITLE: (Reinforcement) learning of an odor-place association task
# #+TITLE: Using Reinforcement Learning to solve a place-odor association task
#+author: Andrea Pierr√©
#+date: April 4, 2023
* HEADER :noexport:
#+SETUPFILE: ./style.org

* Collaborators
:PROPERTIES:
:UNNUMBERED: notoc
:END:
** Collaborators
:PROPERTIES:
:BEAMER_opt: plain
:END:
#+begin_export latex
%\addtocounter{framenumber}{-1}
#+end_export
#+begin_export latex
\begin{adjustbox}{max width=\textwidth, keepaspectratio}
\begin{minipage}[t]{0.2\textwidth}
\center
\includegraphics[height=0.2\textheight]{img/matt-nassar.jpg}\\
\scriptsize
Matt Nassar
\end{minipage}
\begin{minipage}[t]{0.2\textwidth}
\center
\includegraphics[height=0.2\textheight]{img/niloufar-razmi.jpeg}\\
\scriptsize
Niloufar Razmi
\end{minipage}
\begin{minipage}[t]{0.2\textwidth}
\center
\includegraphics[height=0.2\textheight]{img/jason-ritt.jpg}\\
\scriptsize
Jason Ritt
\end{minipage}
\begin{minipage}[t]{0.2\textwidth}
\center
\includegraphics[height=0.2\textheight]{img/olivia.jpg}\\
\scriptsize
Olivia McKissick
\end{minipage}
\begin{minipage}[t]{0.2\textwidth}
\center
\includegraphics[height=0.2\textheight]{img/alex-fleischmann.jpg}\\
\scriptsize
Alex Fleischmann
\end{minipage}
\end{adjustbox}
#+end_export
* Context
:PROPERTIES:
:UNNUMBERED: notoc
:END:
#+begin_export latex
{%
\setbeamertemplate{background canvas}{\includegraphics[height=\paperheight]{img/rooms1.svg.png}}
\begin{frame}[fragile]{Odor-place association}
\end{frame}
}
#+end_export
* Context
:PROPERTIES:
:UNNUMBERED: notoc
:END:
#+begin_export latex
{%
\setbeamertemplate{background canvas}{\includegraphics[height=\paperheight]{img/rooms2.svg.png}}
\begin{frame}[fragile]{Odor-place association}
\addtocounter{framenumber}{-1}
\end{frame}
}
#+end_export
* Context
:PROPERTIES:
:UNNUMBERED: notoc
:END:
** The LEC is key to sensory associations and spatial memory
*** Text :BMCOL:
:PROPERTIES:
:BEAMER_col: 0.45
:END:
#+begin_export latex
%\pause
%\scriptsize
%\footnotesize
\footnotesize
#+end_export
- *Piriform Cortex* encodes olfactory information
- *Hippocampus* encodes spatial information
- *Lateral Entorhinal Cortex (LEC)* encodes both olfactory & spatial information
*** Image :BMCOL:
:PROPERTIES:
:BEAMER_col: 0.55
:END:
#+ATTR_LaTeX: :width \textwidth
[[file:img/brain.png]]

** Diamond arena experimental setup
#+begin_export latex
\begin{textblock}{0.2}(1,0.071)%
\center
\includegraphics[width=3em]{img/olivia.jpg}\\
\scriptsize
Olivia\\McKissick
\end{textblock}
#+end_export
#+ATTR_LaTeX: :width 0.8\textwidth
[[file:img/physical-diamond-arena.png]]
\to\nbsp{}1P calcium imaging recording on freely moving mice
** Diamond arena olfactory task
#+begin_export latex
\begin{textblock}{0.2}(1,0.071)%
\center%
\includegraphics[width=3em]{img/olivia.jpg}\\
\scriptsize
Olivia\\McKissick
\end{textblock}
#+end_export
*** Allocentric :BMCOL:
:PROPERTIES:
:BEAMER_col: 0.5
:BEAMER_opt: [t]
:END:
#+begin_export latex
\center
\vspace{-2em}
#+end_export
Allocentric\\
(go west/east)
#+begin_export latex
\vspace{-1.5em}
#+end_export
#+ATTR_LaTeX: :width 0.8\textwidth
[[file:img/RL_env-allo-task.drawio.png]]
*** Egocentric :BMCOL:
:PROPERTIES:
:BEAMER_col: 0.5
:BEAMER_opt: [t]
:END:
** Diamond arena olfactory task
#+begin_export latex
\addtocounter{framenumber}{-1}
\begin{textblock}{0.2}(1,0.071)%
\center%
\includegraphics[width=3em]{img/olivia.jpg}\\
\scriptsize
Olivia\\McKissick
\end{textblock}
#+end_export
*** Allocentric :BMCOL:
:PROPERTIES:
:BEAMER_col: 0.5
:BEAMER_opt: [t]
:END:
#+begin_export latex
\center
\vspace{-2em}
#+end_export
Allocentric\\
(go west/east)
#+begin_export latex
\vspace{-1.5em}
#+end_export
#+ATTR_LaTeX: :width 0.8\textwidth
[[file:img/RL_env-allo-task.drawio.png]]
*** Egocentric :BMCOL:
:PROPERTIES:
:BEAMER_col: 0.5
:BEAMER_opt: [t]
:END:
#+begin_export latex
\center
\vspace{-2em}
#+end_export
Egocentric\\
(go right/left)
#+begin_export latex
\vspace{-2em}
#+end_export
#+ATTR_LaTeX: :width 0.8\textwidth
[[file:img/RL_env-ego-task.drawio.png]]
** What is Reinforcement Learning and why use it ?
:PROPERTIES:
:BEAMER_act: [<+->]
:END:
*** Diagram :BMCOL:
:PROPERTIES:
:BEAMER_col: 0.55
:END:
#+ATTR_LaTeX: :width \textwidth

#+INCLUDE: "./RL.tex" src latex

*** Ideas :BMCOL:
:PROPERTIES:
:BEAMER_col: 0.45
:END:
#+begin_export latex
\footnotesize
#+end_export
- Theoretical framework hypothesized to be implemented in the brain
- Tool to model behavior
- Goal of the agent : maximize rewards
- Natural fit for behavioral experiments involving rewards and learning

** RL maps states to actions
#+begin_export latex
\center
\begin{tikzpicture}
    \node[anchor=south west,inner sep=0] (image) at (0,0) {\includegraphics[height=\textheight]{img/RL_mapping-1.drawio.png}};
\end{tikzpicture}
#+end_export
*** COMMENT Equation :BMCOL:
:PROPERTIES:
:BEAMER_col: 0.5
:END:
#+begin_export latex
\begin{adjustbox}{max width=\columnwidth, keepaspectratio}
\( Q^{new}(s_t, a_t) \longleftarrow Q(s_t, a_t) + \underbrace{\alpha}_\text{learning rate}\overbrace{(\underbrace{r_t}_\text{reward} + \gamma \operatorname*{max}_a Q(s_{t+1, a}) - Q(s_t, a_t))}^\text{temporal difference} \)
\end{adjustbox}\\[1em]
\begin{adjustbox}{max width=\columnwidth, keepaspectratio}
%\begin{align}
\( \mathbf{Q} = \mathrm{\mathbf{x}} \cdot \mathbf{W} \)
%\end{align}
\end{adjustbox}
#+end_export
** RL maps states to actions
#+begin_export latex
\center
\addtocounter{framenumber}{-1}
\begin{tikzpicture}
    \node[anchor=south west,inner sep=0] (image) at (0,0) {\includegraphics[height=\textheight]{img/RL_mapping-1.drawio.png}};
    \draw[RedBrown,ultra thick,rounded corners] (0,4) rectangle (3,4.7);
\end{tikzpicture}
#+end_export
** RL maps states to actions
#+begin_export latex
\addtocounter{framenumber}{-1}
\center
\begin{tikzpicture}
    \node[anchor=south west,inner sep=0] (image) at (0,0) {\includegraphics[height=\textheight]{img/RL_mapping-1.drawio.png}};
    \draw[RedBrown,ultra thick,rounded corners] (4.5,3.5) rectangle (7,4.5);
\end{tikzpicture}
#+end_export
** RL maps states to actions
#+begin_export latex
\addtocounter{framenumber}{-1}
\center
\begin{tikzpicture}
    \node[anchor=south west,inner sep=0] (image) at (0,0) {\includegraphics[height=\textheight]{img/RL_mapping-all.drawio.png}};
    \draw[RedBrown,ultra thick,rounded corners] (4.5,0.5) rectangle (7,2.5);
\end{tikzpicture}
#+end_export
** RL maps states to actions
#+begin_export latex
\addtocounter{framenumber}{-1}
\center
\begin{tikzpicture}
    \node[anchor=south west,inner sep=0] (image) at (0,0) {\includegraphics[height=\textheight]{img/RL_mapping-2.drawio.png}};
    \draw[RedBrown,ultra thick,rounded corners] (0,4) rectangle (3,4.7);
    \draw[RedBrown,ultra thick,rounded corners] (4.5,3.5) rectangle (7,4.5);
\end{tikzpicture}
#+end_export
** \nbsp{}
:PROPERTIES:
:BEAMER_opt: standout
:END:
#+begin_export latex
\raggedright
#+end_export
Which representations are needed by the brain to learn a place-odor association task ?
** The joint representation encodes odor + location
*** Location :BMCOL:
:PROPERTIES:
:BEAMER_col: 0.33
:END:
#+begin_export latex
\begin{center}
Location only
\end{center}
#+end_export
[[file:img/joint-repr-location.drawio.png]]
*** Odor :BMCOL:
:PROPERTIES:
:BEAMER_col: 0.33
:END:
*** Joint :BMCOL:
:PROPERTIES:
:BEAMER_col: 0.33
:END:
** The joint representation encodes odor + location
#+begin_export latex
\addtocounter{framenumber}{-1}
#+end_export
*** Location :BMCOL:
:PROPERTIES:
:BEAMER_col: 0.33
:END:
#+begin_export latex
\begin{center}
Location only
\end{center}
#+end_export
[[file:img/joint-repr-location.drawio.png]]
*** Odor :BMCOL:
:PROPERTIES:
:BEAMER_col: 0.33
:END:
#+begin_export latex
\begin{center}
Odor only
\end{center}
#+end_export
[[file:img/joint-repr-odor.drawio.png]]
*** Joint :BMCOL:
:PROPERTIES:
:BEAMER_col: 0.33
:END:
** The joint representation encodes odor + location
#+begin_export latex
\addtocounter{framenumber}{-1}
#+end_export
*** Location :BMCOL:
:PROPERTIES:
:BEAMER_col: 0.33
:END:
#+begin_export latex
\begin{center}
Location only
\end{center}
#+end_export
[[file:img/joint-repr-location.drawio.png]]
*** Odor :BMCOL:
:PROPERTIES:
:BEAMER_col: 0.33
:END:
#+begin_export latex
\begin{center}
Odor only
\end{center}
#+end_export
[[file:img/joint-repr-odor.drawio.png]]
*** Joint :BMCOL:
:PROPERTIES:
:BEAMER_col: 0.33
:END:
#+begin_export latex
\begin{center}
Joint
\end{center}
#+end_export
[[file:img/joint-repr-joint.drawio.png]]
* COMMENT Question
:PROPERTIES:
:UNNUMBERED: notoc
:END:
#+begin_export latex
\begin{frame}[fragile]{}
\metroset{block=fill}
\begin{exampleblock}{Question}
Which representations are needed by the brain to learn a place-odor association task ?
\end{exampleblock}
\end{frame}
#+end_export
* Modeling & preliminary results
** The model
*** Allocentric :BMCOL:
:PROPERTIES:
:BEAMER_col: 0.5
:END:
#+begin_export latex
\center
#+end_export
Allocentric
#+ATTR_LaTeX: :height 0.2\textheight
[[file:img/ego-vs-allo-allo.drawio.png]]
#+ATTR_LaTeX: :width 0.9\textwidth
[[file:img/RL_env-allo-model.drawio.png]]
*** Egocentric :BMCOL:
:PROPERTIES:
:BEAMER_col: 0.5
:END:
** The model
#+begin_export latex
\addtocounter{framenumber}{-1}
#+end_export
*** Allocentric :BMCOL:
:PROPERTIES:
:BEAMER_col: 0.5
:END:
#+begin_export latex
\center
#+end_export
Allocentric
#+ATTR_LaTeX: :height 0.2\textheight
[[file:img/ego-vs-allo-allo.drawio.png]]
#+ATTR_LaTeX: :width 0.9\textwidth
[[file:img/RL_env-allo-model.drawio.png]]
*** Egocentric :BMCOL:
:PROPERTIES:
:BEAMER_col: 0.5
:END:
#+begin_export latex
\center
#+end_export
Egocentric
#+ATTR_LaTeX: :height 0.2\textheight
[[file:img/ego-vs-allo-ego.drawio.png]]
#+ATTR_LaTeX: :width 0.9\textwidth
[[file:img/RL_env-ego-model.drawio.png]]
** COMMENT With joint representation
*** \nbsp{}
#+ATTR_LaTeX: :height 0.4\textheight
[[file:img/rewards-steps-allo-joint-repr.png]]
\to The agent learns to solve the task
** COMMENT Without joint representation
*** \nbsp{}
#+ATTR_LaTeX: :height 0.4\textheight
[[file:img/rewards-steps-allo-no-joint-repr.png]]
\to The agent is unable to solve the task
** Maximizing rewards
*** Without joint representation
:PROPERTIES:
:BEAMER_col: 0.5
:BEAMER_opt: [t]
:END:
#+begin_export latex
\begin{center}
Without joint representation
\end{center}
#+end_export
#+ATTR_LaTeX: :width \textwidth
[[file:img/rewards-allo-no-joint-repr.png]]
\to The agent doesn't learn
*** With joint representation
:PROPERTIES:
:BEAMER_col: 0.5
:BEAMER_opt: [t]
:END:
#+begin_export latex
\begin{center}
With joint representation
\end{center}
#+end_export
#+ATTR_LaTeX: :width \textwidth
[[file:img/rewards-allo-joint-repr.png]]
\to The agent learns to solve the task

** Minimizing the number of steps to solve the task
*** Without joint representation
:PROPERTIES:
:BEAMER_col: 0.5
:BEAMER_opt: [t]
:END:
#+begin_export latex
\begin{center}
Without joint representation
\end{center}
#+end_export
#+ATTR_LaTeX: :width \textwidth
[[file:img/steps-allo-no-joint-repr.png]]
\to The agent doesn't learn
*** With joint representation
:PROPERTIES:
:BEAMER_col: 0.5
:BEAMER_opt: [t]
:END:
#+begin_export latex
\begin{center}
With joint representation
\end{center}
#+end_export
#+ATTR_LaTeX: :width \textwidth
[[file:img/steps-allo-joint-repr.png]]
\to The agent learns to solve the task

** What policy did the agent learned ?
#+begin_export latex
\vspace{-7em}
#+end_export
*** Left
:PROPERTIES:
:BEAMER_col: 0.5
:BEAMER_opt: [t]
:END:
#+ATTR_LaTeX: :height 0.4\textheight
[[file:img/policy-allo-north-light.png]]
*** Right
:PROPERTIES:
:BEAMER_col: 0.5
:BEAMER_opt: [t]
:END:
#+ATTR_LaTeX: :height 0.4\textheight
[[file:img/policy-allo-south-light.png]]
** What policy did the agent learned ?
#+begin_export latex
\addtocounter{framenumber}{-1}
#+end_export
*** Left
:PROPERTIES:
:BEAMER_col: 0.5
:BEAMER_opt: [t]
:END:
#+ATTR_LaTeX: :height 0.4\textheight
[[file:img/policy-allo-north-light.png]]
[[file:img/policy-allo-odor-A.png]]
*** Right
:PROPERTIES:
:BEAMER_col: 0.5
:BEAMER_opt: [t]
:END:
#+ATTR_LaTeX: :height 0.4\textheight
[[file:img/policy-allo-south-light.png]]
[[file:img/policy-allo-odor-B.png]]
#+begin_export latex
\begin{textblock}{0.2}(0.29,0.525)%
\includegraphics[height=1em]{img/banana.png}
\end{textblock}
\begin{textblock}{0.2}(0.855,0.525)%
\includegraphics[height=1em]{img/lemon.png}
\end{textblock}
#+end_export
* Next steps
** Our RL model so far
*** Diagram :BMCOL:
:PROPERTIES:
:BEAMER_col: 0.55
:BEAMER_opt: [t]
:END:
#+ATTR_LaTeX: :width \columnwidth
#+INCLUDE: "./RL-tab.tex" src latex

*** Ideas :BMCOL:
:PROPERTIES:
:BEAMER_col: 0.45
:BEAMER_opt: [t]
:END:
#+begin_export latex
\footnotesize
#+end_export
- Tabular model that maps states to actions
- No generalization \to\nbsp{}each state needs to be visited by the agent to compute a prediction of getting a future reward

** Next step : from tabular RL to deep RL
*** Diagram :BMCOL:
:PROPERTIES:
:BEAMER_col: 0.55
:BEAMER_opt: [t]
:END:
#+ATTR_LaTeX: :width \columnwidth
#+INCLUDE: "./RL-nn.tex" src latex

*** Ideas :BMCOL:
:PROPERTIES:
:BEAMER_col: 0.45
:BEAMER_opt: [t]
:END:
#+begin_export latex
\footnotesize
#+end_export
- Neural network does the mapping from states to actions
- Learn to extract features/representations from the simulation data
- Better generalization \to\nbsp{}the agent does not need to visit each state to compute a prediction of getting a future reward
** What types of representations are in use to solve an odor-place association task ?
#+ATTR_LaTeX: :height 0.4\textheight
[[file:img/exp-vs-simu.drawio.png]]
#+begin_export latex
\vspace{-3em}
#+end_export
*** Experiment :BMCOL:
:PROPERTIES:
:BEAMER_col: 0.5
:BEAMER_opt: [t]
:END:
#+begin_export latex
\begin{center}
\textbf{Experimental data}
\end{center}
#+end_export
\to Look for candidate patterns in the data: place cells, grid cells, odor tuned cells,\dots?
*** Simulation :BMCOL:
:PROPERTIES:
:BEAMER_col: 0.5
:BEAMER_opt: [t]
:END:
#+begin_export latex
\begin{center}
\textbf{Simulation}
\end{center}
#+end_export
\to Compare the experimental data with the representations learned from scratch by the neural network

#+begin_export latex
% \begin{textblock}{5}(-8.5,0.5)
% \begin{minipage}[t]{3em}
% \center
% \includegraphics[height=2em]{img/matt-nassar.jpg}\\
% \scriptsize
% Matt Nassar
% \end{minipage}
% \begin{minipage}[t]{3em}
% \center
% \includegraphics[height=2em]{img/niloufar-razmi.jpeg}\\
% \scriptsize
% Niloufar Razmi
% \end{minipage}
% \end{textblock}
#+end_export

** Summary
:PROPERTIES:
:BEAMER_act: [<+->]
:END:
- LEC as candidate brain area for studying how *odor* & *place* information are integrated in the brain
- We use Reinforcement Learning to model behavior involving rewards and learning
- The *joint representation* is needed to solve an odor-place association task
- We expect to use Deep Reinforcement Learning to investigate other types of representations that may be at play
* Acknowledgments
:PROPERTIES:
:UNNUMBERED: notoc
:END:
#+begin_export latex
{%
\setbeamertemplate{background canvas}{\includegraphics[height=\paperheight]{img/grand-canyon.JPG}}
\begin{frame}[fragile,t, plain]{Acknowledgments}
    \addtocounter{framenumber}{-1}
    %\vspace{1em}
    \begin{columns}[T]
        \begin{column}{0.5\textwidth}
            \begin{tcolorbox}[opacityfill=0.1, arc=0mm, size=fbox, coltext=white, colback=black, colframe=black]
                \small
                \centering
                \textbf{Fleischmann lab}
                \begin{itemize}[noitemsep, before=\color{white}\bfseries]
                    \scriptsize
                    %{\transparent{0.5}\colorbox{white}{%
                    \item Alexander Fleischmann
                    \item Keeley Baker
                    \item Olivia Mckissick
                    \item Tuan Pham
                    \item Simon Daste
                    \item Max Seppo
                    %\item \colorbox{white}{\transparent{0.2}Sara Zeppilli}
                    \item Sara Zeppilli
                    \item Nell Klimpert
                    \item Erin Meyers
                    \item Eseosa Uwaifo
                    \item Camille Donoho
                    \item Timothy Pyon
                \end{itemize}
            \end{tcolorbox}
            %\vspace{5em}
            \includegraphics[height=1.5cm]{img/qr-code.png}\\
            %\colorbox{white}{\footnotesize\transparent{0.5}https://reduced.to/tn9x6}
        \end{column}

        \begin{column}{0.5\textwidth}
            \begin{tcolorbox}[opacityfill=0.1, arc=0mm, size=fbox, coltext=white, colback=black, colframe=black]
                \small
                \centering
                \textbf{Collaborations}
                \begin{itemize}[noitemsep, before=\color{white}\bfseries]
                    \scriptsize
                    \item Matt Nassar
                    \item Jason Ritt
                    \item Niloufar Razmi
                \end{itemize}
            \end{tcolorbox}
        \end{column}
    \end{columns}
\end{frame}
}
#+end_export
* Backup
** Policy learned in the egocentric version
#+begin_export latex
\addtocounter{framenumber}{-1}
#+end_export
[[file:img/policy-ego-joint-repr.png]]
* Feedback :noexport:
** v1
*** What is LEC?
- region
- It seems to have information about
- Lab is working on it and recording
*** First slide with a picture
*** Start with the experiment?
*** Or start with RL or the brain?
*** What is this talk about?
*** Define the problem/example
Learning with association \to I know where to get it
*** Anatomical intro
**** DONE Ask Olivia
**** Hyp/LEC/PCx
*** Hyp
**** Intro of each term
***** LEC
***** Conjunctive
**** Maybe only the question, no hypothesis
**** Follow-up question: what representations might work?
***** Because network
*** We think RL is implemented in the brain
Another player that has a teaching signal == dopamine
Representation we might find in the temporal lobe
Efficient RL + successful solving task
*** Task first
*** Schema with mapping from states to actions
- Animated
- With the equation with pieces highlited on the right
*** Introduce congiuntuve code like Niloufar
*** Present plots sequentially
- Box to highlight?
*** Add a line of the plot's takeaway
*** Declarative title
Ex: Model without joint repr fail to learn the task
*** Show with joit repr before to show what it should get
*** Explain policy with schema of animal and arrows options
*** Add odor + puff of air icons on policy plots
*** States occupancy \to just explain what we could do
*** Back and forth with the model and data
- Where agent/animal spends its time?
*** Now we want to go in these directions
*** What representations can support this learning?
**** Can't separate odor and place encoding
**** Can
*** Replace ticks with categories
*** Design
**** Small multiples
**** General > specific > general
**** Paralellism
**** Ratio of info on the slides
*** Replace Episode by trial
*** Remove 3 times
*** Put steps on the left
*** What it changes it how many steps it taks to get there
*** Add n=3 agents ?
** v2
*** RPE
Put feedback loop for RPE
*** Define allocentric/egocentric
*** Choose color for ego/allo?
*** Animate model for one action
*** Redo Olivia's task to match the model and keep the grid
*** Don't put the policy for no joint repre
*** Explain joint representation
Link joint repr to LEC
If you don't have it you can't solve the task
*** Have slide that explain the feature matrix
*** Don't show the weight matrix
*** Don't show the egocentric results?
Put it in the next steps?
*** Only put egocentric?
*** Pictures of Matt/Niloufar/Olivia
*** RPE schema used to explain why we use the RL framework
*** TODO Missing link between the experiment and why we use RL
*** Coffee instead of flower?
*** We're interested in how the brain solves the this association
*** Explain direct connection between OB and LEC
*** Connectivity
**** OB: olfaction
**** Hyp: spatial location
**** LEC: connects both
*** Summary of results
**** If the no repr the model can't solve the task
*** Saying expectations loud
*** TODO Add a fit to reward plot to show the trend
** v3
*** No connection between coffee & LEC slide
*** TODO What's the motivation? Goals? Why it matters?
*** Question motivated by this and that
*** What do I mean by states?
*** DONE Put Jason/Matt/Niloufar in the first slide
*** DONE No outline, directly coffee
*** DONE Tea in one room, coffee in the other room
*** DONE Agent on the map
Bubble with what it is thinking
Bubble with question mark
*** What happens in the head of the agent?
That's why we show LEC
What states in the head of the agent
*** How does the brain learn to associate olfactory & spatial information
What we think are the major players involved LEC, blabbla
*** Focus on transitions
*** TODO Include only A, B and D in experiment
What do I show the ports? If I don't talk about it, don't need to show
*** DONE Go from brain to schema of the task
*** Animate allocentric schema
*** Show egocentric?
*** Type of infor the mouse is using to solve the task
\to joint repr
What type of information the mouse might keep track of?
*** Path
1. repr to RL
2. RL to repr
*** Didn't explain states on the RL diagram
1. Rl work if you get the right states repr
2. What is the right states repr
3. Then show joint repr slide
*** DONE Animate states that strengthen connections
*** Legend on the policy
*** We also did it with an egocentric action space
*** Walk through allocentric model
*** Same info, two ways to represent the info
In one way it doesn't learn
In the other it learns

** Priorities
*** Title?
*** DONE Intro with coffee/tea/agent
*** Pictures arena
*** Redo task schema
*** DONE Allo vs. ego schema?
*** Plots
**** DONE Fit on plots
**** DONE Odor emoji
**** Legend?
*** DONE Next steps
**** DONE Write clear text?
**** DONE Remake exp vs simulation with loop?
* COMMENT Questions
** neural network
*** Lookup table
** [?] What type of representations?
*** Feature extractions
*** hierarchical combination of features
*** Feature compression
**** Location \to cue
** [?] What type of neural network
*** First make a simple feedforward working
- Already difficult to plug DL with RL
- 2 optimization loops \eq 2 times more problems or bugs that can arise
*** Then we can think of more complex networks, which adds recurrence for example


* COMMENT Add plain option to Beamer TOC
% Local variables:
% org-beamer-outline-frame-options: "plain"
% End:
