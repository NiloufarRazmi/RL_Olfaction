#+TITLE: Learning useful representations to solve a place-odor association task
# #+SUBTITLE: NSGP seminar
# #+SUBTITLE: (Reinforcement) learning of an odor-place association task
# #+TITLE: Using Reinforcement Learning to solve a place-odor association task
#+author: Andrea Pierr√©
#+date: April 4, 2023
* HEADER :noexport:
#+SETUPFILE: ./style.org

* Context of the project
* Context
:PROPERTIES:
:UNNUMBERED: notoc
:END:
#+begin_export latex
{%
\setbeamertemplate{background canvas}{\includegraphics[height=\paperheight]{img/kitchen1.png}}
\begin{frame}[fragile]{Odor-place association}
\end{frame}
}
#+end_export
* Context
:PROPERTIES:
:UNNUMBERED: notoc
:END:
#+begin_export latex
{%
\setbeamertemplate{background canvas}{\includegraphics[height=\paperheight]{img/kitchen2.png}}
\begin{frame}[fragile]{Odor-place association}
\addtocounter{framenumber}{-1}
\end{frame}
}
#+end_export
* Context
:PROPERTIES:
:UNNUMBERED: notoc
:END:
#+begin_export latex
{%
\setbeamertemplate{background canvas}{\includegraphics[height=\paperheight]{img/kitchen3.png}}
\begin{frame}[fragile]{Odor-place association}
\addtocounter{framenumber}{-1}
\end{frame}
}
#+end_export
** The LEC is key to sensory associations and spatial memory
*** Text :BMCOL:
:PROPERTIES:
:BEAMER_col: 0.45
:END:
#+begin_export latex
%\pause
%\scriptsize
%\footnotesize
\footnotesize
#+end_export
- *Piriform* encodes olfactory information
- *Hippocampus* encodes spatial information
- *LEC* encodes both olfactory & spatial information
*** Image :BMCOL:
:PROPERTIES:
:BEAMER_col: 0.55
:END:
#+ATTR_LaTeX: :width \textwidth
[[file:img/brain.png]]

** Diamond arena experimental setup
#+begin_export latex
\begin{textblock}{5}(11,-1.3)
\center
\includegraphics[width=3em]{img/olivia.jpg}\\
\scriptsize
Olivia McKissick
\end{textblock}
#+end_export
#+ATTR_LaTeX: :width 0.8\textwidth
[[file:img/physical-diamond-arena.png]]
** Diamond arena olfactory task
#+begin_export latex
\begin{textblock}{5}(11,-0.5)
\center
\includegraphics[width=3em]{img/olivia.jpg}\\
\scriptsize
Olivia McKissick
\end{textblock}
#+end_export
*** Allocentric :BMCOL:
:PROPERTIES:
:BEAMER_col: 0.5
:BEAMER_opt: [t]
:END:
#+begin_export latex
\center
#+end_export
Allocentric\\
(go west/east)
#+ATTR_LaTeX: :width 0.8\textwidth
[[file:img/allocentric-task.png]]

*** Egocentric :BMCOL:
:PROPERTIES:
:BEAMER_col: 0.5
:BEAMER_opt: [t]
:END:
#+begin_export latex
\center
#+end_export
Egocentric\\
(go right/left)
#+ATTR_LaTeX: :width 0.8\textwidth
[[file:img/egocentric-task.png]]

** What is Reinforcement Learning and why use it ?
:PROPERTIES:
:BEAMER_act: [<+->]
:END:
*** Diagram :BMCOL:
:PROPERTIES:
:BEAMER_col: 0.55
:END:
#+ATTR_LaTeX: :width \textwidth

#+INCLUDE: "./RL.tex" src latex

*** Ideas :BMCOL:
:PROPERTIES:
:BEAMER_col: 0.45
:END:
#+begin_export latex
\footnotesize
#+end_export
- Theoretical framework hypothesized to be implemented in the brain
- Tool to model behavior
- Goal of the agent : maximize rewards
- Natural fit for behavioral experiments involving rewards and learning

** RL maps states to optimized actions
*** Illustration :BMCOL:
:PROPERTIES:
:BEAMER_col: 0.5
:END:
#+ATTR_LaTeX: :height 0.8\textheight
[[./img/RL_mapping.drawio.png]]
*** Equation :BMCOL:
:PROPERTIES:
:BEAMER_col: 0.5
:END:
#+begin_export latex
\begin{adjustbox}{max width=\columnwidth, keepaspectratio}
\( Q^{new}(s_t, a_t) \longleftarrow Q(s_t, a_t) + \underbrace{\alpha}_\text{learning rate}\overbrace{(\underbrace{r_t}_\text{reward} + \gamma \operatorname*{max}_a Q(s_{t+1, a}) - Q(s_t, a_t))}^\text{temporal difference} \)
\end{adjustbox}\\[1em]
\begin{adjustbox}{max width=\columnwidth, keepaspectratio}
%\begin{align}
\( \mathbf{Q} = \mathrm{\mathbf{x}} \cdot \mathbf{W} \)
%\end{align}
\end{adjustbox}
#+end_export
* Question
:PROPERTIES:
:UNNUMBERED: notoc
:END:
#+begin_export latex
\begin{frame}[fragile]{}
\metroset{block=fill}
\begin{exampleblock}{Question}
Which representations are needed by the brain to learn a place-odor association task ?
\end{exampleblock}
\end{frame}
#+end_export
* Modeling & preliminary results
** Allocentric vs. Egocentric
*** Allocentric :BMCOL:
:PROPERTIES:
:BEAMER_col: 0.5
:END:
#+begin_export latex
\center
#+end_export
Allocentric
*** Egocentric :BMCOL:
:PROPERTIES:
:BEAMER_col: 0.5
:END:
#+begin_export latex
\center
#+end_export
Egocentric
*** \nbsp{}
[[file:img/ego-vs-allo.jpg]]
** The model
*** Allocentric :BMCOL:
:PROPERTIES:
:BEAMER_col: 0.5
:END:
#+begin_export latex
\center
#+end_export
Allocentric
#+ATTR_LaTeX: :width \textwidth
[[file:img/RL_env-allo-model.drawio.png]]
*** Egocentric :BMCOL:
:PROPERTIES:
:BEAMER_col: 0.5
:END:
** The model
#+begin_export latex
\addtocounter{framenumber}{-1}
#+end_export
*** Allocentric :BMCOL:
:PROPERTIES:
:BEAMER_col: 0.5
:END:
#+begin_export latex
\center
#+end_export
Allocentric
#+ATTR_LaTeX: :width \textwidth
[[file:img/RL_env-allo-model.drawio.png]]
*** Egocentric :BMCOL:
:PROPERTIES:
:BEAMER_col: 0.5
:END:
#+begin_export latex
\center
#+end_export
Egocentric
#+ATTR_LaTeX: :width \textwidth
[[file:img/RL_env-ego-model.drawio.png]]
** The joint representation encodes odor + location
[[file:img/joint-repr.drawio.png]]
** COMMENT With joint representation
*** \nbsp{}
#+ATTR_LaTeX: :height 0.4\textheight
[[file:img/rewards-steps-allo-joint-repr.png]]
\to The agent learns to solve the task
** COMMENT Without joint representation
*** \nbsp{}
#+ATTR_LaTeX: :height 0.4\textheight
[[file:img/rewards-steps-allo-no-joint-repr.png]]
\to The agent is unable to solve the task
** Minimizing the number of steps to solve the task
*** With joint representation
:PROPERTIES:
:BEAMER_col: 0.5
:BEAMER_opt: [t]
:END:
#+begin_export latex
\begin{center}
With joint representation
\end{center}
#+end_export
#+ATTR_LaTeX: :width \textwidth
[[file:img/steps-allo-joint-repr.png]]
\to The agent learns to solve the task

*** Without joint representation
:PROPERTIES:
:BEAMER_col: 0.5
:BEAMER_opt: [t]
:END:
#+begin_export latex
\begin{center}
Without joint representation
\end{center}
#+end_export
#+ATTR_LaTeX: :width \textwidth
[[file:img/steps-allo-no-joint-repr.png]]
\to The agent doesn't learn
** Maximizing rewards
*** With joint representation
:PROPERTIES:
:BEAMER_col: 0.5
:BEAMER_opt: [t]
:END:
#+begin_export latex
\begin{center}
With joint representation
\end{center}
#+end_export
#+ATTR_LaTeX: :width \textwidth
[[file:img/rewards-allo-joint-repr.png]]
\to The agent learns to solve the task

*** Without joint representation
:PROPERTIES:
:BEAMER_col: 0.5
:BEAMER_opt: [t]
:END:
#+begin_export latex
\begin{center}
Without joint representation
\end{center}
#+end_export
#+ATTR_LaTeX: :width \textwidth
[[file:img/rewards-allo-no-joint-repr.png]]
\to The agent doesn't learn
** What policy did the agent learned ?
#+begin_export latex
\vspace{-7em}
#+end_export
*** Left
:PROPERTIES:
:BEAMER_col: 0.5
:BEAMER_opt: [t]
:END:
#+ATTR_LaTeX: :height 0.4\textheight
[[file:img/policy-allo-north-light.png]]
*** Right
:PROPERTIES:
:BEAMER_col: 0.5
:BEAMER_opt: [t]
:END:
#+ATTR_LaTeX: :height 0.4\textheight
[[file:img/policy-allo-south-light.png]]
** What policy did the agent learned ?
*** Left
:PROPERTIES:
:BEAMER_col: 0.5
:BEAMER_opt: [t]
:END:
#+ATTR_LaTeX: :height 0.4\textheight
[[file:img/policy-allo-north-light.png]]
[[file:img/policy-allo-odor-A.png]]
*** Right
:PROPERTIES:
:BEAMER_col: 0.5
:BEAMER_opt: [t]
:END:
#+ATTR_LaTeX: :height 0.4\textheight
[[file:img/policy-allo-south-light.png]]
[[file:img/policy-allo-odor-B.png]]
* Next steps
** What we have done so far
#+begin_export latex
\center
#+end_export
#+INCLUDE: "./RL-tab.tex" src latex
** From tabular RL to deep RL
#+begin_export latex
\center
\addtocounter{framenumber}{-1}
#+end_export
#+INCLUDE: "./RL-nn.tex" src latex
** What types of representations are in use to solve the odor-place association task ?
*** Experiment :BMCOL:
:PROPERTIES:
:BEAMER_col: 0.5
:BEAMER_opt: [t]
:END:
#+begin_export latex
\begin{center}
Experiment
\end{center}
#+end_export
#+ATTR_LaTeX: :height 0.25\textheight
[[file:img/place-cells-grid-cells.jpg.png]]
\to Look for candidate patterns in the data: place cells, grid cells,\dots?
*** Simulation :BMCOL:
:PROPERTIES:
:BEAMER_col: 0.5
:BEAMER_opt: [t]
:END:
#+begin_export latex
\begin{center}
Simulation
\end{center}
#+end_export
#+ATTR_LaTeX: :height 0.25\textheight
[[file:img/nn.svg.png]]
\to Compare the data with the representations learned from scratch by the neural network

#+begin_export latex
% \begin{textblock}{5}(-8.5,0.5)
% \begin{minipage}[t]{3em}
% \center
% \includegraphics[height=2em]{img/matt-nassar.jpg}\\
% \scriptsize
% Matt Nassar
% \end{minipage}
% \begin{minipage}[t]{3em}
% \center
% \includegraphics[height=2em]{img/niloufar-razmi.jpeg}\\
% \scriptsize
% Niloufar Razmi
% \end{minipage}
% \end{textblock}
#+end_export

** Summary
:PROPERTIES:
:BEAMER_act: [<+->]
:END:
- We record in the LEC which encodes spatial & olfactory information
- Reinforcement Learning can be a useful tool to model behavior involving rewards and learning
- The joint representation is needed to solve an odor-place location task
* Acknowledgments
:PROPERTIES:
:UNNUMBERED: notoc
:END:
#+begin_export latex
{%
\setbeamertemplate{background canvas}{\includegraphics[height=\paperheight]{img/grand-canyon.JPG}}
\begin{frame}[fragile,t, plain]{Acknowledgments}
    \vspace{1em}
    \begin{columns}[T]
        \begin{column}{0.5\textwidth}
            \begin{itemize}
                \small
                \item Fleischmann lab
                \begin{itemize}
                    \tiny
                    \item Alexander Fleischmann
                    \item Keeley Baker
                    \item Olivia Mckissick
                    \item Tuan Pham
                    \item Simon Daste
                    \item Max Seppo
                    %\item \colorbox{white}{\transparent{0.2}Sara Zeppilli}
                    \item Sara Zeppilli
                    \item Nell Klimpert
                    \item Erin Meyers
                    \item Eseosa Uwaifo
                    \item Camille Donoho
                    \item Timothy Pyon
                \end{itemize}
            \end{itemize}
            \vspace{5em}
            \includegraphics[height=1.5cm]{img/qr-code.png}\\
            %\colorbox{white}{\footnotesize\transparent{0.5}https://reduced.to/tn9x6}
        \end{column}

        \begin{column}{0.5\textwidth}
            \begin{itemize}
                \small
                \item Collaborations
                \begin{itemize}
                    \tiny
                    \item Matt Nassar
                    \item Jason Ritt
                    \item Niloufar Razmi
                \end{itemize}
            \end{itemize}
        \end{column}
    \end{columns}
\end{frame}
}
#+end_export
* Feedback :noexport:
** v1
*** What is LEC?
- region
- It seems to have information about
- Lab is working on it and recording
*** First slide with a picture
*** Start with the experiment?
*** Or start with RL or the brain?
*** What is this talk about?
*** Define the problem/example
Learning with association \to I know where to get it
*** Anatomical intro
**** DONE Ask Olivia
**** Hyp/LEC/PCx
*** Hyp
**** Intro of each term
***** LEC
***** Conjunctive
**** Maybe only the question, no hypothesis
**** Follow-up question: what representations might work?
***** Because network
*** We think RL is implemented in the brain
Another player that has a teaching signal == dopamine
Representation we might find in the temporal lobe
Efficient RL + successful solving task
*** Task first
*** Schema with mapping from states to actions
- Animated
- With the equation with pieces highlited on the right
*** Introduce congiuntuve code like Niloufar
*** Present plots sequentially
- Box to highlight?
*** Add a line of the plot's takeaway
*** Declarative title
Ex: Model without joint repr fail to learn the task
*** Show with joit repr before to show what it should get
*** Explain policy with schema of animal and arrows options
*** Add odor + puff of air icons on policy plots
*** States occupancy \to just explain what we could do
*** Back and forth with the model and data
- Where agent/animal spends its time?
*** Now we want to go in these directions
*** What representations can support this learning?
**** Can't separate odor and place encoding
**** Can
*** Replace ticks with categories
*** Design
**** Small multiples
**** General > specific > general
**** Paralellism
**** Ratio of info on the slides
*** Replace Episode by trial
*** Remove 3 times
*** Put steps on the left
*** What it changes it how many steps it taks to get there
*** Add n=3 agents ?
** v2
*** RPE
Put feedback loop for RPE
*** Define allocentric/egocentric
*** Choose color for ego/allo?
*** Animate model for one action
*** Redo Olivia's task to match the model and keep the grid
*** Don't put the policy for no joint repre
*** Explain joint representation
Link joint repr to LEC
If you don't have it you can't solve the task
*** Have slide that explain the feature matrix
*** Don't show the weight matrix
*** Don't show the egocentric results?
Put it in the next steps?
*** Only put egocentric?
*** Pictures of Matt/Niloufar/Olivia
*** RPE schema used to explain why we use the RL framework
*** TODO Missing link between the experiment and why we use RL
*** Coffee instead of flower?
*** We're interested in how the brain solves the this association
*** Explain direct connection between OB and LEC
*** Connectivity
**** OB: olfaction
**** Hyp: spatial location
**** LEC: connects both
*** Summary of results
**** If the no repr the model can't solve the task
*** Saying expectations loud
*** TODO Add a fit to reward plot to show the trend
** v3
*** No connection between coffee & LEC slide
*** TODO What's the motivation? Goals? Why it matters?
*** Question motivated by this and that
*** What do I mean by states?
*** TODO Put Jason/Matt/Niloufar in the first slide
*** TODO No outline, directly coffee
*** Tea in one room, coffee in the other room
*** Agent on the map
Bubble with what it is thinking
Bubble with question mark
*** What happens in the head of the agent?
That's why we show LEC
What states in the head of the agent
*** How does the brain learn to know olfactory information to associate
What we think are the major players involved LEC, blabbla
*** Focus on transitions
*** Include only A, B and D in experiment
What do I show the ports? If I don't talk about it, don't need to show
*** Go from brain to schema of the task
*** Animate allocentric schema
*** Show egocentric?
*** Type of infor the mouse is using to solve the task
\to joint repr
What type of information the mouse might keep track of?
*** Path
1. repr to RL
2. RL to repr
*** Didn't explain states on the RL diagram
Rl work if you get the right states repr
What is the right states repr
Then show joint repr slide
*** Animate states that strengthen connections
*** Legend on the policy
*** We also did it with an egocentric action space
*** Walk through allocentric model
*** Same info, two ways to represent the info
In one way it doesn't learn
In the other it learns

** Priorities
*** Title?
*** Intro with coffee/tea/agent
*** Pictures arena
*** Redo task schema
*** Allo vs. ego schema?
*** Plots
**** Fit on plots
**** DONE Odor emoji
**** Legend?
*** Next steps
**** Write clear text?
**** Remake exp vs simulation with loop?

* COMMENT Add plain option to Beamer TOC
% Local variables:
% org-beamer-outline-frame-options: "plain"
% End:
