% Created 2023-04-03 Mon 02:06
% Intended LaTeX compiler: lualatex
\documentclass[bigger]{beamer}
\usepackage{graphicx}
\usepackage{longtable}
\usepackage{wrapfig}
\usepackage{rotating}
\usepackage[normalem]{ulem}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{capt-of}
\usepackage{hyperref}
\usetheme[progressbar=foot, sectionpage=none, numbering=fraction]{metropolis}
\usepackage{tikz}
\usepackage{booktabs}
\usepackage{adjustbox}
\usepackage{diagbox}
\usepackage{latexcolors}
\usetikzlibrary{automata, positioning, arrows, arrows.meta}
\usepackage{diagbox}
\usepackage{dsfont}
\usepackage{fontawesome5}
\usepackage{color}
\usepackage{transparent}
\usepackage{textpos}
\usepackage{tcolorbox}
\usepackage{enumitem}
\setlist[itemize]{label=\textbullet}
\usepackage{mathtools}
\usepackage[mathrm=sym]{unicode-math}
\definecolor{RedBrown}{RGB}{192, 4, 4} \setbeamercolor{progress bar}{fg=RedBrown} \setbeamercolor{title separator}{fg=RedBrown}
\setbeamercolor{progress bar in head/foot}{fg=RedBrown} \setbeamercolor{progress bar in section page}{fg=RedBrown} \setbeamercolor{alerted text}{fg=RedBrown}
\pretocmd{\tableofcontents}{\thispagestyle{empty}}{}{}
\addtocounter{framenumber}{-1}
\usepackage{listings}
\usepackage{xcolor}
\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{HTML}{f0f0f0}
\lstdefinestyle{mystyle}{
backgroundcolor=\color{backcolour},
commentstyle=\color{codegreen},
keywordstyle=\color{magenta},
numberstyle=\tiny\color{codegray},
stringstyle=\color{codepurple},
basicstyle=\ttfamily,
breakatwhitespace=false,
breaklines=true,
captionpos=b,
keepspaces=true,
numbers=none,
numbersep=5pt,
showspaces=false,
showstringspaces=false,
showtabs=false,
tabsize=2
}
\lstset{style=mystyle}
\usetheme{default}
\author{Andrea Pierré}
\date{April 4, 2023}
\title{Learning useful representations to solve a place-odor association task}
\institute{Fleischmann Lab}
\titlegraphic{\hfill\includegraphics[height=1.5cm]{img/Brown Logo_2016_2 Color Process ST_1300.png}\vspace{8em}\flushright\includegraphics[height=1.5cm]{img/qr-code.png}}
\setbeamercovered{transparent=10}
\hypersetup{
 pdfauthor={Andrea Pierré},
 pdftitle={Learning useful representations to solve a place-odor association task},
 pdfkeywords={},
 pdfsubject={},
 pdfcreator={Emacs 28.2 (Org mode 9.6)}, 
 pdflang={English}}
\begin{document}

\maketitle
\section*{Collaborators}
\label{sec:org4c85f77}
\begin{frame}[label={sec:org7c5cc75},plain]{Collaborators}
%\addtocounter{framenumber}{-1}
\begin{adjustbox}{max width=\textwidth, keepaspectratio}
\begin{minipage}[t]{0.2\textwidth}
\center
\includegraphics[height=0.2\textheight]{img/matt-nassar.jpg}\\
\scriptsize
Matt Nassar
\end{minipage}
\begin{minipage}[t]{0.2\textwidth}
\center
\includegraphics[height=0.2\textheight]{img/niloufar-razmi.jpeg}\\
\scriptsize
Niloufar Razmi
\end{minipage}
\begin{minipage}[t]{0.2\textwidth}
\center
\includegraphics[height=0.2\textheight]{img/jason-ritt.jpg}\\
\scriptsize
Jason Ritt
\end{minipage}
\begin{minipage}[t]{0.2\textwidth}
\center
\includegraphics[height=0.2\textheight]{img/olivia.jpg}\\
\scriptsize
Olivia McKissick
\end{minipage}
\begin{minipage}[t]{0.2\textwidth}
\center
\includegraphics[height=0.2\textheight]{img/alex-fleischmann.jpg}\\
\scriptsize
Alex Fleischmann
\end{minipage}
\end{adjustbox}
\end{frame}
\section*{Context}
\label{sec:orgc4d8512}
{%
\setbeamertemplate{background canvas}{\includegraphics[height=\paperheight]{img/rooms1.svg.png}}
\begin{frame}[fragile]{Odor-place association}
\end{frame}
}
\section*{Context}
\label{sec:org609a786}
{%
\setbeamertemplate{background canvas}{\includegraphics[height=\paperheight]{img/rooms2.svg.png}}
\begin{frame}[fragile]{Odor-place association}
\addtocounter{framenumber}{-1}
\end{frame}
}
\section*{Context}
\label{sec:orgb70afd6}
\begin{frame}[label={sec:org9f9f41f}]{The LEC is key to sensory associations and spatial memory}
\begin{columns}
\begin{column}{0.45\columnwidth}
%\pause
%\scriptsize
%\footnotesize
\footnotesize
\begin{itemize}
\item \alert{Piriform} encodes olfactory information
\item \alert{Hippocampus} encodes spatial information
\item \alert{LEC} encodes both olfactory \& spatial information
\end{itemize}
\end{column}
\begin{column}{0.55\columnwidth}
\begin{center}
\includegraphics[width=\textwidth]{img/brain.png}
\end{center}
\end{column}
\end{columns}
\end{frame}

\begin{frame}[label={sec:org6329642}]{Diamond arena olfactory task}
\begin{textblock}{5}(11,-0.5)
\center
\includegraphics[width=3em]{img/olivia.jpg}\\
\scriptsize
Olivia McKissick
\end{textblock}
\begin{columns}
\begin{column}[t]{0.5\columnwidth}
\center
Allocentric\\
(go west/east)
\begin{center}
\includegraphics[width=0.8\textwidth]{img/allocentric-task.png}
\end{center}
\end{column}

\begin{column}[t]{0.5\columnwidth}
\center
Egocentric\\
(go right/left)
\begin{center}
\includegraphics[width=0.8\textwidth]{img/egocentric-task.png}
\end{center}
\end{column}
\end{columns}
\end{frame}

\begin{frame}[label={sec:orge8d0364}]{Diamond arena experimental setup}
\begin{textblock}{5}(11,-1.3)
\center
\includegraphics[width=3em]{img/olivia.jpg}\\
\scriptsize
Olivia McKissick
\end{textblock}
\begin{center}
\includegraphics[width=0.8\textwidth]{img/physical-diamond-arena.png}
\end{center}
\end{frame}
\begin{frame}[<+->][label={sec:org61052e0}]{What is Reinforcement Learning and why use it ?}
\begin{columns}
\begin{column}{0.55\columnwidth}
% \usepackage{fontawesome5}
\usetikzlibrary{positioning,fit,arrows}


\tikzset{
    %Define standard arrow tip
    >=latex,
    %Define style for boxes
    punkt/.style={
           rectangle,
           rounded corners,
           draw=black, very thick,
           text width=7.5em,
           minimum height=2em,
           text centered},
    % Define arrow style
    pil/.style={
           ->,
           thick,}
}

\begin{adjustbox}{max width=\columnwidth, keepaspectratio}
    \begin{tikzpicture}[node distance=3em, auto,]
     %nodes
        \node (center) {};
        \node[punkt, above=of center] (agent) {Agent \faIcon{robot}};
        \node[punkt,below=of center] (environment) {Environment \faIcon{globe}};
        \node[right=8em of center, align=center] (action) {Action\\$a_t$};
        \node[left=8em of center, align=center] (state_reward) {State, Reward\\$s_t$, $r_t$};

        \path[pil]
        (state_reward.east) edge [->, bend left=45] node {} (agent.west)
        (environment.west) edge [- , bend left=45] node {} (state_reward.east)
        (action.west) edge [->, bend left=45] node {} (environment.east)
        (agent.east) edge [-, bend left=45] node {} (action.west);
    \end{tikzpicture}
\end{adjustbox}
\end{column}

\begin{column}{0.45\columnwidth}
\footnotesize
\begin{itemize}
\item Theoretical framework hypothesized to be implemented in the brain
\item Tool to model behavior
\item Goal of the agent : maximize rewards
\item Natural fit for behavioral experiments involving rewards and learning
\end{itemize}
\end{column}
\end{columns}
\end{frame}

\begin{frame}[label={sec:orgd202fdc}]{RL maps states to actions}
\center
\begin{tikzpicture}
    \node[anchor=south west,inner sep=0] (image) at (0,0) {\includegraphics[height=\textheight]{img/RL_mapping-1.drawio.png}};
\end{tikzpicture}
\end{frame}
\begin{frame}[label={sec:orgfe5e54f}]{RL maps states to actions}
\center
\addtocounter{framenumber}{-1}
\begin{tikzpicture}
    \node[anchor=south west,inner sep=0] (image) at (0,0) {\includegraphics[height=\textheight]{img/RL_mapping-1.drawio.png}};
    \draw[RedBrown,ultra thick,rounded corners] (0,4) rectangle (3,4.7);
\end{tikzpicture}
\end{frame}
\begin{frame}[label={sec:orgb5d9837}]{RL maps states to actions}
\addtocounter{framenumber}{-1}
\center
\begin{tikzpicture}
    \node[anchor=south west,inner sep=0] (image) at (0,0) {\includegraphics[height=\textheight]{img/RL_mapping-1.drawio.png}};
    \draw[RedBrown,ultra thick,rounded corners] (4.5,3.5) rectangle (7,4.5);
\end{tikzpicture}
\end{frame}
\begin{frame}[label={sec:org64f4796}]{RL maps states to actions}
\addtocounter{framenumber}{-1}
\center
\begin{tikzpicture}
    \node[anchor=south west,inner sep=0] (image) at (0,0) {\includegraphics[height=\textheight]{img/RL_mapping-all.drawio.png}};
    \draw[RedBrown,ultra thick,rounded corners] (4.5,0.5) rectangle (7,2.5);
\end{tikzpicture}
\end{frame}
\begin{frame}[label={sec:orgfdb242e}]{RL maps states to actions}
\addtocounter{framenumber}{-1}
\center
\begin{tikzpicture}
    \node[anchor=south west,inner sep=0] (image) at (0,0) {\includegraphics[height=\textheight]{img/RL_mapping-2.drawio.png}};
    \draw[RedBrown,ultra thick,rounded corners] (0,4) rectangle (3,4.7);
\end{tikzpicture}
\end{frame}
\begin{frame}[label={sec:org8a9e386}]{The joint representation encodes odor + location}
\begin{columns}
\begin{column}{0.33\columnwidth}
\begin{center}
Location only
\end{center}
\begin{center}
\includegraphics[width=.9\linewidth]{img/joint-repr-location.drawio.png}
\end{center}
\end{column}
\begin{column}{0.33\columnwidth}
\end{column}
\begin{column}{0.33\columnwidth}
\end{column}
\end{columns}
\end{frame}
\begin{frame}[label={sec:orgff1af98}]{The joint representation encodes odor + location}
\addtocounter{framenumber}{-1}
\begin{columns}
\begin{column}{0.33\columnwidth}
\begin{center}
Location only
\end{center}
\begin{center}
\includegraphics[width=.9\linewidth]{img/joint-repr-location.drawio.png}
\end{center}
\end{column}
\begin{column}{0.33\columnwidth}
\begin{center}
Odor only
\end{center}
\begin{center}
\includegraphics[width=.9\linewidth]{img/joint-repr-odor.drawio.png}
\end{center}
\end{column}
\begin{column}{0.33\columnwidth}
\end{column}
\end{columns}
\end{frame}
\begin{frame}[label={sec:org269dcca}]{The joint representation encodes odor + location}
\addtocounter{framenumber}{-1}
\begin{columns}
\begin{column}{0.33\columnwidth}
\begin{center}
Location only
\end{center}
\begin{center}
\includegraphics[width=.9\linewidth]{img/joint-repr-location.drawio.png}
\end{center}
\end{column}
\begin{column}{0.33\columnwidth}
\begin{center}
Odor only
\end{center}
\begin{center}
\includegraphics[width=.9\linewidth]{img/joint-repr-odor.drawio.png}
\end{center}
\end{column}
\begin{column}{0.33\columnwidth}
\begin{center}
Joint
\end{center}
\begin{center}
\includegraphics[width=.9\linewidth]{img/joint-repr-joint.drawio.png}
\end{center}
\end{column}
\end{columns}
\end{frame}
\begin{frame}[label={sec:org8b06670},standout]{~}
\raggedright
Which representations are needed by the brain to learn a place-odor association task ?
\end{frame}
\section{Modeling \& preliminary results}
\label{sec:org4a9499c}
\begin{frame}[label={sec:orgcf978ef}]{Allocentric vs. Egocentric}
\begin{columns}
\begin{column}{0.5\columnwidth}
\begin{center}
Allocentric
\end{center}
\begin{center}
\includegraphics[width=.9\linewidth]{img/ego-vs-allo-allo.drawio.png}
\end{center}
\end{column}
\begin{column}{0.5\columnwidth}
\begin{center}
Egocentric
\end{center}
\begin{center}
\includegraphics[width=.9\linewidth]{img/ego-vs-allo-ego.drawio.png}
\end{center}
\end{column}
\end{columns}
\end{frame}
\begin{frame}[label={sec:orgcc08fb9}]{The model}
\begin{columns}
\begin{column}{0.5\columnwidth}
\center
Allocentric
\begin{center}
\includegraphics[width=\textwidth]{img/RL_env-allo-model.drawio.png}
\end{center}
\end{column}
\begin{column}{0.5\columnwidth}
\end{column}
\end{columns}
\end{frame}
\begin{frame}[label={sec:org1827034}]{The model}
\addtocounter{framenumber}{-1}
\begin{columns}
\begin{column}{0.5\columnwidth}
\center
Allocentric
\begin{center}
\includegraphics[width=\textwidth]{img/RL_env-allo-model.drawio.png}
\end{center}
\end{column}
\begin{column}{0.5\columnwidth}
\center
Egocentric
\begin{center}
\includegraphics[width=\textwidth]{img/RL_env-ego-model.drawio.png}
\end{center}
\end{column}
\end{columns}
\end{frame}
\begin{frame}[label={sec:org192be0e}]{Maximizing rewards}
\begin{columns}
\begin{column}[t]{0.5\columnwidth}
\begin{center}
Without joint representation
\end{center}
\begin{center}
\includegraphics[width=\textwidth]{img/rewards-allo-no-joint-repr.png}
\end{center}
\(\to\) The agent doesn't learn
\end{column}
\begin{column}[t]{0.5\columnwidth}
\begin{center}
With joint representation
\end{center}
\begin{center}
\includegraphics[width=\textwidth]{img/rewards-allo-joint-repr.png}
\end{center}
\(\to\) The agent learns to solve the task
\end{column}
\end{columns}
\end{frame}

\begin{frame}[label={sec:org3560e2b}]{Minimizing the number of steps to solve the task}
\begin{columns}
\begin{column}[t]{0.5\columnwidth}
\begin{center}
Without joint representation
\end{center}
\begin{center}
\includegraphics[width=\textwidth]{img/steps-allo-no-joint-repr.png}
\end{center}
\(\to\) The agent doesn't learn
\end{column}
\begin{column}[t]{0.5\columnwidth}
\begin{center}
With joint representation
\end{center}
\begin{center}
\includegraphics[width=\textwidth]{img/steps-allo-joint-repr.png}
\end{center}
\(\to\) The agent learns to solve the task
\end{column}
\end{columns}
\end{frame}

\begin{frame}[label={sec:org3de0d40}]{What policy did the agent learned ?}
\vspace{-7em}
\begin{columns}
\begin{column}[t]{0.5\columnwidth}
\begin{center}
\includegraphics[height=0.4\textheight]{img/policy-allo-north-light.png}
\end{center}
\end{column}
\begin{column}[t]{0.5\columnwidth}
\begin{center}
\includegraphics[height=0.4\textheight]{img/policy-allo-south-light.png}
\end{center}
\end{column}
\end{columns}
\end{frame}
\begin{frame}[label={sec:org1fe4b7e}]{What policy did the agent learned ?}
\addtocounter{framenumber}{-1}
\begin{columns}
\begin{column}[t]{0.5\columnwidth}
\begin{center}
\includegraphics[height=0.4\textheight]{img/policy-allo-north-light.png}
\end{center}
\begin{center}
\includegraphics[height=0.4\textheight]{img/policy-allo-odor-A.png}
\end{center}
\end{column}
\begin{column}[t]{0.5\columnwidth}
\begin{center}
\includegraphics[height=0.4\textheight]{img/policy-allo-south-light.png}
\end{center}
\begin{center}
\includegraphics[height=0.4\textheight]{img/policy-allo-odor-B.png}
\end{center}
\end{column}
\end{columns}
\end{frame}
\section{Next steps}
\label{sec:org25eb2d8}
\begin{frame}[label={sec:orgc661b19}]{What we have done so far}
\begin{columns}
\begin{column}[t]{0.55\columnwidth}
% \usepackage{fontawesome5}
\usetikzlibrary{positioning,fit,arrows}


\tikzset{
    %Define standard arrow tip
    >=latex,
    %Define style for boxes
    punkt/.style={
           rectangle,
           rounded corners,
           draw=black, very thick,
           text width=7.5em,
           minimum height=2em,
           text centered},
    % Define arrow style
    pil/.style={
           ->,
           thick,}
}

\begin{adjustbox}{max width=\textwidth, keepaspectratio}
    \begin{tikzpicture}[node distance=3em, auto,]
     %nodes
        \node (center) {};
        \node[punkt, above=of center] (agent) {Agent \faIcon{robot}};
        % \node at (0,3.7) {\includegraphics[height=6em]{./img/nn.svg.png}};
        \node [above=-0.2em of agent] {\includegraphics[height=8em]{./img/Q-table.png}};
        \node[punkt,below=of center] (environment) {Environment \faIcon{globe}};
        \node[right=8em of center, align=center] (action) {Action\\$a_t$};
        \node[left=8em of center, align=center] (state_reward) {State, Reward\\$s_t$, $r_t$};
        \node [below=-0.2em of environment] {\includegraphics[height=8em]{./img/RL_env-allo-model.drawio.png}};

        \path[pil]
        (state_reward.east) edge [->, bend left=45] node {} (agent.west)
        (environment.west) edge [- , bend left=45] node {} (state_reward.east)
        (action.west) edge [->, bend left=45] node {} (environment.east)
        (agent.east) edge [-, bend left=45] node {} (action.west);
    \end{tikzpicture}
\end{adjustbox}
\end{column}

\begin{column}[t]{0.45\columnwidth}
\footnotesize
\begin{itemize}
\item Behavioral model only
\item Tabular model that maps states to actions
\item All states need to be visited by the agent to propagate the prediction of getting a future reward \(\to\)~not what happens in the brain
\end{itemize}
\end{column}
\end{columns}
\end{frame}

\begin{frame}[label={sec:org1e89f75}]{From tabular RL to deep RL}
\begin{columns}
\begin{column}[t]{0.55\columnwidth}
% \usepackage{fontawesome5}
\usetikzlibrary{positioning,fit,arrows}


\tikzset{
    %Define standard arrow tip
    >=latex,
    %Define style for boxes
    punkt/.style={
           rectangle,
           rounded corners,
           draw=black, very thick,
           text width=7.5em,
           minimum height=2em,
           text centered},
    % Define arrow style
    pil/.style={
           ->,
           thick,}
}

\begin{adjustbox}{max width=\textwidth, keepaspectratio}
    \begin{tikzpicture}[node distance=3em, auto,]
     %nodes
        \node (center) {};
        \node[punkt, above=of center] (agent) {Agent \faIcon{robot}};
        % \node at (0,3.7) {\includegraphics[height=6em]{./img/nn.svg.png}};
        \node [above=-0.2em of agent] {\includegraphics[height=8em]{./img/nn.svg.png}};
        \node[punkt,below=of center] (environment) {Environment \faIcon{globe}};
        \node[right=8em of center, align=center] (action) {Action\\$a_t$};
        \node[left=8em of center, align=center] (state_reward) {State, Reward\\$s_t$, $r_t$};
        \node [below=-0.2em of environment] {\includegraphics[height=8em]{./img/RL_env-allo-model.drawio.png}};

        \path[pil]
        (state_reward.east) edge [->, bend left=45] node {} (agent.west)
        (environment.west) edge [- , bend left=45] node {} (state_reward.east)
        (action.west) edge [->, bend left=45] node {} (environment.east)
        (agent.east) edge [-, bend left=45] node {} (action.west);
    \end{tikzpicture}
\end{adjustbox}
\end{column}

\begin{column}[t]{0.45\columnwidth}
\footnotesize
\begin{itemize}
\item Behavioral + neural model
\item Neural network that maps states to actions
\item Extract features from the simulation data
\item Not all states need to be visited by the agent to propagate the prediction of getting a future reward \(\to\)~closer to the brain
\end{itemize}
\end{column}
\end{columns}
\end{frame}
\begin{frame}[label={sec:org70fa57d}]{What types of representations are in use to solve an odor-place association task ?}
\begin{center}
\includegraphics[height=0.4\textheight]{img/exp-vs-simu.drawio.png}
\end{center}
\vspace{-3em}
\begin{columns}
\begin{column}[t]{0.5\columnwidth}
\begin{center}
Experiment
\end{center}
\(\to\) Look for candidate patterns in the data: place cells, grid cells,\dots{}?
\end{column}
\begin{column}[t]{0.5\columnwidth}
\begin{center}
Simulation
\end{center}
\(\to\) Compare the data with the representations learned from scratch by the neural network

% \begin{textblock}{5}(-8.5,0.5)
% \begin{minipage}[t]{3em}
% \center
% \includegraphics[height=2em]{img/matt-nassar.jpg}\\
% \scriptsize
% Matt Nassar
% \end{minipage}
% \begin{minipage}[t]{3em}
% \center
% \includegraphics[height=2em]{img/niloufar-razmi.jpeg}\\
% \scriptsize
% Niloufar Razmi
% \end{minipage}
% \end{textblock}
\end{column}
\end{columns}
\end{frame}

\begin{frame}[<+->][label={sec:orgd73df92}]{Summary}
\begin{itemize}
\item We record in the LEC because it encodes spatial \& olfactory information
\item Reinforcement Learning is a useful framework to model behavior involving rewards and learning
\item The joint representation is needed to solve an odor-place association task
\item We hope to use Deep Reinforcement Learning to better understand the representations that are at play in this type of task
\end{itemize}
\end{frame}
\section*{Acknowledgments}
\label{sec:orgceeb156}
{%
\setbeamertemplate{background canvas}{\includegraphics[height=\paperheight]{img/grand-canyon.JPG}}
\begin{frame}[fragile,t, plain]{Acknowledgments}
    \addtocounter{framenumber}{-1}
    %\vspace{1em}
    \begin{columns}[T]
        \begin{column}{0.5\textwidth}
            \begin{tcolorbox}[opacityfill=0.1, arc=0mm, size=fbox, coltext=white, colback=black, colframe=black]
                \small
                \centering
                \textbf{Fleischmann lab}
                \begin{itemize}[noitemsep, before=\color{white}\bfseries]
                    \scriptsize
                    %{\transparent{0.5}\colorbox{white}{%
                    \item Alexander Fleischmann
                    \item Keeley Baker
                    \item Olivia Mckissick
                    \item Tuan Pham
                    \item Simon Daste
                    \item Max Seppo
                    %\item \colorbox{white}{\transparent{0.2}Sara Zeppilli}
                    \item Sara Zeppilli
                    \item Nell Klimpert
                    \item Erin Meyers
                    \item Eseosa Uwaifo
                    \item Camille Donoho
                    \item Timothy Pyon
                \end{itemize}
            \end{tcolorbox}
            %\vspace{5em}
            \includegraphics[height=1.5cm]{img/qr-code.png}\\
            %\colorbox{white}{\footnotesize\transparent{0.5}https://reduced.to/tn9x6}
        \end{column}

        \begin{column}{0.5\textwidth}
            \begin{tcolorbox}[opacityfill=0.1, arc=0mm, size=fbox, coltext=white, colback=black, colframe=black]
                \small
                \centering
                \textbf{Collaborations}
                \begin{itemize}[noitemsep, before=\color{white}\bfseries]
                    \scriptsize
                    \item Matt Nassar
                    \item Jason Ritt
                    \item Niloufar Razmi
                \end{itemize}
            \end{tcolorbox}
        \end{column}
    \end{columns}
\end{frame}
}
\section{Backup}
\label{sec:orgb0cc0f8}
\begin{frame}[label={sec:org44f3849}]{Egocentric policy}
\addtocounter{framenumber}{-1}
\begin{center}
\includegraphics[width=.9\linewidth]{img/policy-ego-joint-repr.png}
\end{center}
\end{frame}
\end{document}
