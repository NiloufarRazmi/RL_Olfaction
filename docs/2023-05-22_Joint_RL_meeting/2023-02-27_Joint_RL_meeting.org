#+TITLE: Joint RL meeting
#+author: Andrea PierrÃ©
#+date: May 22^{nd}, 2023
#+EMAIL: andrea_pierre@brown.edu
* HEADER :noexport:
#+SETUPFILE: ./style.org

* Reducing the number of features in function approximation
** Features matrix -- allocentric agent
\to Reduced from 100 to 25 locations + 4 cues
#+ATTR_LaTeX: :height 0.8\textheight
[[file:img/FuncApprox-allo-features-matrix.png]]
** Rewards and steps -- allocentric agent
#+ATTR_LaTeX: :width \textwidth
[[file:img/FuncApprox-allo-rewards-steps.png]]
** Q-values learned -- allocentric agent
[[file:img/FuncApprox-allo-q-values.png]]
** Features matrix -- egocentric agent
\to Reduced from 400 to 100 locations (25 locations x 4 head directions) + 16 cues (4 cues x 4 head directions)
#+ATTR_LaTeX: :height 0.75\textheight
[[file:img/FuncApprox-ego-features-matrix.png]]
** Rewards and steps -- egocentric agent
#+ATTR_LaTeX: :width \textwidth
[[file:img/FuncApprox-ego-rewards-steps.png]]
** Q-values learned -- egocentric agent
[[file:img/FuncApprox-ego-q-values.png]]
* Deep Reinforcement Learning first draft
** Toy task : Random Walk 1D
[[file:img/RandomWalk1D.png]]
** Network used
#+begin_export latex
\begin{center}
\begin{adjustbox}{max height=\textheight, keepaspectratio}
% NEURAL NETWORK no text
\begin{tikzpicture}[x=2.2cm,y=1.4cm]
  \message{^^JNeural network without text}
  \readlist\Nnod{1,5,2} % array of number of nodes per layer

  \message{^^J  Layer}
  \foreachitem \N \in \Nnod{ % loop over layers
    \def\lay{\Ncnt} % alias of index of current layer
    \pgfmathsetmacro\prev{int(\Ncnt-1)} % number of previous layer
    \message{\lay,}
    \foreach \i [evaluate={\y=\N/2-\i; \x=\lay; \n=\nstyle;}] in {1,...,\N}{ % loop over nodes

      % NODES
      \node[node \n] (N\lay-\i) at (\x,\y) {};

      % CONNECTIONS
      \ifnum\lay>1 % connect to previous layer
        \foreach \j in {1,...,\Nnod[\prev]}{ % loop over nodes in previous layer
          \draw[connect,white,line width=1.2] (N\prev-\j) -- (N\lay-\i);
          \draw[connect] (N\prev-\j) -- (N\lay-\i);
          %\draw[connect] (N\prev-\j.0) -- (N\lay-\i.180); % connect to left
        }
      \fi % else: nothing to connect first layer

    }
  }

  % LABELS
  \node[above=1,align=center,mygreen!60!black] at (N1-1.90) {input\\[-0.2em]layer\\[-0.2em](state)};
  \node[above=0.5,align=center,myblue!60!black] at (N2-1.90) {hidden layer};
  \node[above=1,align=center,myred!60!black] at (N\Nnodlen-1.90) {output\\[-0.2em]layer\\[-0.2em](actions)};

\end{tikzpicture}
\end{adjustbox}
\end{center}
#+end_export
** Rewards and steps
[[file:img/DRL-rewards-steps.png]]
** Q-values learned
#+ATTR_LaTeX: :width \textwidth
[[file:img/DRL-q-values.png]]
** \nbsp{}
:PROPERTIES:
:BEAMER_opt: standout
:END:
Questions ?
* COMMENT Add plain option to Beamer TOC
% Local variables:
% org-beamer-outline-frame-options: "plain"
% End:
* Feedback :noexport:
