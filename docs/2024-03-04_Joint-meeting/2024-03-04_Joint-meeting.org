#+TITLE: Joint meeting
# #+SUBTITLE: Deep dive into deep RL
#+author: Andrea Pierr√©
#+date: March 4^{th}, 2024
* HEADER :noexport:
#+SETUPFILE: ./style.org

* Online Deep RL training
** Rewards & steps
#+ATTR_LaTeX: :width \linewidth
[[file:img/steps-and-rewards.png]]
** Why is it converging now?
:PROPERTIES:
:BEAMER_act: [<+->]
:END:
- Lights cues in the state?
- Start training once replay buffer is full (5000 transitions) instead of when there are enough transitions for a batch (32 transitions)
- Soft update of the networks weights (instead of sharp transition)
- Huber loss instead of mean squared error \to should be less sensible to outliers
- *Remove ReLU on output layer!*
** Loss, rewards & steps distributions, exploration/exploitation rate
[[file:img/steps-and-rewards-distrib.png]]
*** Left :BMCOL:
:PROPERTIES:
:BEAMER_col: 0.4
:END:
[[file:img/loss.png]]
*** Right :BMCOL:
:PROPERTIES:
:BEAMER_col: 0.4
:END:
[[file:img/exploration-rate.png]]
** Policy learned
#+ATTR_LaTeX: :width \linewidth
[[file:img/policy.png]]
* Generalization experiment
** Training only in the lower triangle
#+ATTR_LaTeX: :width \linewidth
[[file:img/steps-and-rewards-lower-only.png]]
** Training only in the lower triangle then switch to the upper triangle
*** Left :BMCOL:
:PROPERTIES:
:BEAMER_col: 0.5
:END:
#+ATTR_LaTeX: :height 0.4\textheight
[[file:img/exploration-rate_upper-then-lower1.png]]
#+ATTR_LaTeX: :height 0.4\textheight
[[file:img/exploration-rate_upper-then-lower2.png]]
*** Right :BMCOL:
:PROPERTIES:
:BEAMER_col: 0.5
:END:
#+ATTR_LaTeX: :height 0.4\textheight
[[file:img/loss_upper-then-lower1.png]]
#+ATTR_LaTeX: :height 0.4\textheight
[[file:img/loss_upper-then-lower2.png]]
** Training only in the lower triangle then switch to the upper triangle
[[file:img/steps-and-rewards_upper-then-lower1.png]]
[[file:img/steps-and-rewards_upper-then-lower2.png]]
* Discussion
** Points of discussion
:PROPERTIES:
:BEAMER_act: [<+->]
:END:
- Debrief from the meeting with Thomas
- Topics of discussion for future meetings?
  - How to compare neural data with simulation data?
  - Journal club (e.g. MINDS paper, etc.)
  - Any other topics to add?
** \nbsp{}
:PROPERTIES:
:BEAMER_opt: standout
:END:
Thanks!

* COMMENT Add plain option to Beamer TOC
% Local variables:
% org-beamer-outline-frame-options: "plain"
% End:

* Feedback :noexport:
** TODO Policy learned over time
** See where are major weights changing
** TODO Check allo/ego experiment
*** Check if the network prefer ego or allo
*** How to computationally represent ego/allo?
*** How does the weights compare to full arena/lower/flipped
**** Could use ego or allo depending of the conditions?
** What are the factors that influence generalization?
** Plans
*** Niloufar next
*** Topics on email
