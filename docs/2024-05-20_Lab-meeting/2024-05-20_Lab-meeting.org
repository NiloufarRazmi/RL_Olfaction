#+MACRO: faicon \faicon{$1}
#+MACRO: col \colorbox{black!15!white}{[$1]}
#+TITLE: Research plan
#+SUBTITLE: Lab meeting
#+author: Andrea Pierré
#+date: May 20, 2024
* HEADER :noexport:
#+SETUPFILE: ./style.org

* Context {{{faicon(question-circle)}}}

** TODO Why modeling?
:PROPERTIES:
:BEAMER_act: [<+->]
:END:
- Posit: You understand a system if you can simulate it
#+begin_quote
What I cannot create, I do not understand. --Richard Feynman
#+end_quote
- If you have a good enough model you may uncover mechanisms that explain a phenomena
  - Without a model \to you're limited to describe the *how*
  - With a model \to you may be able to explain the *why*
- Test hypothesis
- Abstraction of the system: makes you think of the parameters/inputs/outputs
- Find out what is needed to reproduce experimental results, what explains those results

** What do we want to know?
:PROPERTIES:
:BEAMER_act: [<+->]
:END:
- Understand what the network learns
  \to What *function* does it learns?
- How the constrains of the task affect learning & the representations learned?
- Does the network learn something related to the real neurons? (million {{{faicon(dollar)}}}{{{faicon(dollar)}}}{{{faicon(dollar)}}} question)
** Compositional hypothesis
:PROPERTIES:
:BEAMER_act: [<+->]
:END:
- Does the network learn a generalizable policy? \to\nbsp{}How to test it?
  - From indexed locations (current) to coordinate system
  - Merged actions space
** Compositional hypothesis
[[file:img/env_new-triangle-task.drawio.png]]
** Implementation
[[file:img/nn.drawio.png]]
** Example episode
[[file:img/env_new-steps.drawio.png]]
* Experiments & expected results {{{faicon(eyedropper)}}} {{{faicon(area-chart)}}}
** 1) How training impacts the representations learned?
:PROPERTIES:
:BEAMER_act: [<+->]
:END:
- Feed both coordinates information (Cartesian & polar) to the input layer (+ merge actions spaces in a common one)
- Train on left/right task \to we expect the weights are close to zero on Cartesian representation?
- Train on east/west task \to we expect the weights are close to zero on polar representation?
** 1) How training impacts the representations learned?
[[file:img/exp1-weights-heatmap.png]]
** 2) Does the network learn a coordinate system?
:PROPERTIES:
:BEAMER_act: [<+->]
:END:
1. After training, move the population of agents in a translated coordinate system
   \to we expect the population of agents to be able to solve the task with zero shot learning
2. Train with both coordinates information (Cartesian & polar), after training feed incorrect polar angles
   - On the left/right task \to we expect the population of agents still solves the task consistently
   - On the east/west task \to we expect the network won't converge to a stable policy (i.e all the agents don't solve the task consistently)
** 2) Does the network learn a coordinate system?
[[file:img/exp2-boxplot.png]]
** 2) Does the network learn a coordinate system?
[[file:img/angles-to-activations.png]]
* Roadmap {{{faicon(road)}}}
** Experiments table
#+begin_export latex
\scriptsize
#+end_export
| Experiment                                         | Agents | Hours estimation |
|----------------------------------------------------+--------+------------------|
| left/right Cartesian coordinates from center arena |     30 |                6 |
| left/right Cartesian coordinates from 3 ports      |     30 |                6 |
| east/west polar coordinates from center arena      |     30 |                6 |
| east/west polar coordinates from 3 ports           |     30 |                6 |
|----------------------------------------------------+--------+------------------|
| No translation                                     |     30 |                6 |
| Cartesian translated                               |     30 |                6 |
| Polar translated                                   |     30 |                6 |
| left/right correct angle                           |     30 |                6 |
| left/right incorrect angle                         |     30 |                6 |
| east/west correct angle                            |     30 |                6 |
| east/west incorrect angle                          |     30 |                6 |
|----------------------------------------------------+--------+------------------|
| Total                                              |    330 |               66 |
#+TBLFM: @13$2=vsum(@2..@12)::@13$3=vsum(@2..@12)

** Milestones/how to get there
:PROPERTIES:
:BEAMER_act: [<+->]
:END:
1. Rewrite the environment(s) {{{faicon(star)}}}{{{faicon(star)}}}{{{faicon(star-o)}}}
   1. Code logic for new environment {{{col($\textasciitilde$1 week)}}}
   2. Check everything works as expected (unit testing) {{{col($\textasciitilde$1 week)}}}
   3. Bugs? {{{col($\textasciitilde$1 week)}}}
   4. Baseline training on new environment (convergence, hyperparameter tweaking, etc.) {{{faicon(star)}}}{{{faicon(star)}}}{{{faicon(star)}}}{{{faicon(warning)}}} {{{col(1 week -- 1 month)}}}
2. Experiments
   1. Task code {{{faicon(star)}}}{{{faicon(star-o)}}}{{{faicon(star-o)}}} {{{col($\textasciitilde$1 week)}}}
   2. Training {{{faicon(star)}}}{{{faicon(star)}}}{{{faicon(star-o)}}}{{{faicon(warning)}}} {{{col($\textasciitilde$2 week)}}}
   3. Analysis code {{{faicon(star)}}}{{{faicon(star)}}}{{{faicon(star-o)}}} {{{col($\textasciitilde$2 week)}}}
** Planning
#+ATTR_LaTeX: :width \textwidth
#+INCLUDE: "./planning.tex" src latex
** \nbsp{}
:PROPERTIES:
:BEAMER_opt: standout
:END:
Thanks!

* COMMENT Add plain option to Beamer TOC
% Local variables:
% org-beamer-outline-frame-options: "plain"
% End:

* Feedback :noexport:
** TODO Meeting
Move 31 May to 17th June
1.5h
11am
Niloufar/Matt
Alex grant presentation after 17th?
** DONE Sketch steps
*** How that changes in the coordinate systems
*** Instead of static
*** Leave the static sketch on the left
*** What does it change? What do we gain?
** No one-hot encoded, need to be x & y
** Probabilistic population coding?
10 neurons how it represent
** Polar
*** From north
*** From reward port
** 3 polar + 3 cartesian
** Continuous values for angles
** Check DQN continuous/discrete
** Tuning
*** We expect the weights are close to zero on Cartesian/polar representation?
**** Representation == identify neurons tuned to Cartesian/polar inputs
**** Synthetic electrophysiology
*** Third layer tuned to?
**** Identify neurons type cart/polar sensitive
**** Is this neuron sensitive to polar input?
**** Give it all possible inputs
**** TODO Function that auto identify the tuning
** Incorrect angle \to what does it mean?
*** Polar flip north to South
** Translation experiment
*** Add more tiles -5 to 5 every 1 \to -5 to 5 every 0.5
Network should have learn something else than digits
** How many variations of agents are needed
** DONE Table with conditions
** Keep polar in the same direction for now when changing
** 2 to 5 different conditions, which ones?
** Training/planning
*** Step two: train network
*** Steps 3: only inference
** Trouver l'angle à partir de la longueur des côtés du triangle:
#+begin_src
length_sin = a
length_cos = b
alpha = atan(length_sin/length_cos)*180/pi
#+end_src
