#+TITLE: Lab meeting
#+SUBTITLE: /Robust representations for olfactory-spatial association learning/
#+author: Andrea Pierr√©
#+date: March 11, 2025
* HEADER :noexport:
#+SETUPFILE: ./style.org

* Project recap
** The LEC is key to sensory associations and spatial memory
*** Text :BMCOL:
:PROPERTIES:
:BEAMER_col: 0.45
:END:
#+begin_export latex
\footnotesize
#+end_export
- *Piriform Cortex* encodes olfactory information
- *Hippocampus* encodes spatial information
- *Lateral Entorhinal Cortex (LEC)* encodes both olfactory & spatial information
*** Image :BMCOL:
:PROPERTIES:
:BEAMER_col: 0.55
:END:
#+ATTR_LaTeX: :width \textwidth
[[file:img/brain.png]]

#+begin_export latex
\begin{textblock}{5}(0.5,14.5)%
\tiny
Poo et al., 2022\\
Bitzenhofer et al., 2022\\
Lee et al., 2021
\end{textblock}
#+end_export

** Half triangle task for olfactory-spatial association learning
*** Left
:PROPERTIES:
:BEAMER_col: 0.33
:BEAMER_opt: [c]
:END:
#+begin_export latex
\includegraphics[width=\linewidth, keepaspectratio, trim={0cm 0cm 28cm 0cm}, clip]{img/video-picture.png}
#+end_export
*** Center
:PROPERTIES:
:BEAMER_col: 0.33
:BEAMER_opt: [c]
:END:
#+begin_export latex
\includegraphics[width=0.9\linewidth, keepaspectratio, trim={11cm 18cm 40cm 13cm}, clip]{img/task-east-west.png}
#+end_export
*** Right
:PROPERTIES:
:BEAMER_col: 0.33
:BEAMER_opt: [c]
:END:
#+begin_export latex
\includegraphics[width=0.9\linewidth, keepaspectratio, trim={3cm 2cm 4cm 4cm}, clip]{img/task-left-right.jpeg}
#+end_export

** Deep Reinforcement Learning model
#+ATTR_LaTeX: :height 0.95\textheight
[[file:img/nn.drawio.png]]
** Cartesian/polar duplicated coordinates experiment
#+ATTR_LaTeX: :height 0.6\textheight
[[file:img/RL_env-cartesian-polar.drawio.png]]
#+begin_export latex
\footnotesize
\vspace{-1em}
#+end_export
- 3 actions: $\Leftarrow \quad \Uparrow \quad \Rightarrow$
- Duplicated coordinates inputs:
  - Cartesian coordinates from north & south port
  - Polar coordinates from north & south port
** Questions & Hypothesis
#+begin_export latex
\metroset{block=fill}
\begin{exampleblock}{Questions}
\begin{itemize}
\item What \alert{function} does the network learn?
\item How the constrains of the task affect learning \& the representations learned?
%\item How this task structure might employ different representations of the action space?
\item How do the representations learned compare between the \emph{in vivo} and the \emph{in silico} neurons?
\end{itemize}
\end{exampleblock}
\pause
\begin{exampleblock}{Hypothesis}
\begin{itemize}
\item The network will use the most efficient coordinate information based on the task
\item The structure of the network's weights will reflect this prioritization of information
\end{itemize}
\end{exampleblock}
#+end_export

** Looking back$\dots$
#+begin_export latex
\footnotesize
#+end_export
#+ATTR_LaTeX: :height 0.5\textheight
[[file:img/mdp.png]]
1. Try to define the Olivia's experiment as a Markov Decision Process (MDP) in Julia
2. 2D gridworld in Python/NumPy
3. Duplicated coordinates in Python/PyTorch

* Cartesian/polar duplicated coordinates experiment
** State space & network architecture
#+ATTR_LaTeX: :height 0.95\textheight
[[file:img/state-space-nn.png]]
** Training
East/West
#+ATTR_LaTeX: :height 0.35\textheight
[[file:img/steps-and-rewards-EastWest.png]]
Left/Right
#+ATTR_LaTeX: :height 0.35\textheight
[[file:img/steps-and-rewards-LeftRight.png]]
** Training checks - East/West
#+ATTR_LaTeX: :width \textwidth
[[file:img/steps-and-rewards-distrib-EastWest.png]]
*** Left
:PROPERTIES:
:BEAMER_col: 0.5
:BEAMER_opt: [c]
:END:
#+ATTR_LaTeX: :width 0.8\textwidth
[[file:img/loss-EastWest.png]]
*** Right
:PROPERTIES:
:BEAMER_col: 0.5
:BEAMER_opt: [c]
:END:
#+ATTR_LaTeX: :width 0.65\textwidth
[[file:img/actions-distribution-EastWest.png]]
** Training checks - Left/Right
#+ATTR_LaTeX: :width \textwidth
[[file:img/steps-and-rewards-distrib-LeftRight.png]]
*** Left
:PROPERTIES:
:BEAMER_col: 0.5
:BEAMER_opt: [c]
:END:
#+ATTR_LaTeX: :width 0.8\textwidth
[[file:img/loss-LeftRight.png]]
*** Right
:PROPERTIES:
:BEAMER_col: 0.5
:BEAMER_opt: [c]
:END:
#+ATTR_LaTeX: :width 0.65\textwidth
[[file:img/actions-distribution-LeftRight.png]]
** Agent behavior
*** Left
:PROPERTIES:
:BEAMER_col: 0.3
:BEAMER_opt: [c]
:END:
#+ATTR_LaTeX: :height 0.28\textheight
[[file:img/trajectory-0-0-LeftRight.png]]
#+ATTR_LaTeX: :height 0.28\textheight
[[file:img/trajectory-0-120-LeftRight.png]]
#+ATTR_LaTeX: :height 0.28\textheight
[[file:img/trajectory-0-350-LeftRight.png]]
*** Right
:PROPERTIES:
:BEAMER_col: 0.3
:BEAMER_opt: [c]
:END:
#+ATTR_LaTeX: :height 0.28\textheight
[[file:img/trajectory-0-0-EastWest.png]]
#+ATTR_LaTeX: :height 0.28\textheight
[[file:img/trajectory-0-120-EastWest.png]]
#+ATTR_LaTeX: :height 0.28\textheight
[[file:img/trajectory-0-350-EastWest.png]]
* What does the network learn?
** Activations learned - East/West
#+ATTR_LaTeX: :height 0.9\textheight
[[file:img/activations-learned-EastWest.png]]
** Activations learned - Left/Right
#+ATTR_LaTeX: :height 0.9\textheight
[[file:img/activations-learned-LeftRight.png]]
** TODO Cluster by action space
** TODO Other clustering method
** TODO Use the behavior as proxy -- Perturbation experiment
:PROPERTIES:
:BEAMER_act: [<+->]
:END:
- Perturb the Cartesian/polar part of the input on a trained agent and look at how the agent behaves (x4 experiments)
- Expectation:
  - Left/right task:
    - With the *Cartesian* inputs perturbed \to agent's performance unchanged
    - With the *polar* inputs perturbed \to agent's performance degrades
  - East/west task:
    - With the *polar* inputs perturbed \to agent's performance unchanged
    - With the *Cartesian* inputs perturbed \to agent's performance degrades
** TODO Use the behavior as proxy -- Perturbation experiment
:PROPERTIES:
:BEAMER_act: [<+->]
:END:
- Cartesian perturbation
- Polar perturbation
  - Simulation does not end \to haven't figured out why yet
** TODO Next steps
** COMMENT Neural representations?
[[file:~/Projects/DRL-olfaction/docs/expected cart-polar activations on both tasks.png]]
- Need for some causal framework?
** \nbsp{}
:PROPERTIES:
:BEAMER_opt: standout
:END:
Questions ?
* COMMENT Add plain option to Beamer TOC
% Local variables:
% org-beamer-outline-frame-options: "plain"
% End:

* Feedback :noexport:

** Need for some causal framework?
- [[https://doi.org/10.1038/s42256-020-0218-x]]
- [[https://doi.org/10.31235/osf.io/aeszf]]
- [[https://github.com/kochbj/Deep-Learning-for-Causal-Inference]]

** TODO Metrics for ablation study
*** Performance histogram
*** Percent correct
*** Shift in behavior
*** Number of steps
** TODO Conflicting information
*** 1 set of coord is right, the other is wrong
*** See if the agent follow one or the other
** Cosine input or x node
*** What's the distrib coming on the sine
*** Multidim problem
*** Look for sensitivity coming in the first layer
** Derive of any input wrt input
*** Avg over playback of the agent
*** How sensitive is the agent for this task
** XAI
*** Deepdream
**** What input maximally drive a particular node
** Try to understand the weights more than the activations
*** Weights are the structure of the network
*** Cluster the weights of the network?
** TODO Clustering
*** Cluster by action space
*** Cluster if moved the agent closer to goal or not
**** Break by task phases
**** before cue after cue
*** Target: E/W or L/R
**** Supervised clustering
**** Across all the layers
*** Other type of clustering?
**** Not hierarchical clustering
**** Fix some condition
