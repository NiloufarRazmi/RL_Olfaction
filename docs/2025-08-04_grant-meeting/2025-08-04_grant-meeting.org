#+TITLE: /Robust representations for olfactory-spatial association learning/
# #+SUBTITLE: Grant review
#+author: Andrea Pierr√©
#+date: August 04, 2025
* HEADER :noexport:
#+SETUPFILE: ./style.org
* Project recap
** The LEC is key to sensory associations and spatial memory
*** Text :BMCOL:
:PROPERTIES:
:BEAMER_col: 0.45
:END:
#+begin_export latex
\footnotesize
#+end_export
- *Piriform Cortex* encodes olfactory information
- *Hippocampus* encodes spatial information
- *Lateral Entorhinal Cortex (LEC)* encodes both olfactory & spatial information
*** Image :BMCOL:
:PROPERTIES:
:BEAMER_col: 0.55
:END:
#+ATTR_LaTeX: :width \textwidth
[[file:medias/brain.png]]

#+begin_export latex
\begin{textblock}{5}(0.5,14.5)%
\tiny
Poo et al., 2022\\
Bitzenhofer et al., 2022\\
Lee et al., 2021
\end{textblock}
#+end_export

** Half triangle task for olfactory-spatial association learning
*** Left
:PROPERTIES:
:BEAMER_col: 0.33
:BEAMER_opt: [c]
:END:
#+begin_export latex
\begin{center}
\movie{\includegraphics[width=\linewidth, keepaspectratio, trim={0cm 0cm 28cm 0cm}, clip]{medias/video-picture.png}}{medias/annotatedF03_d35_2022-11-15_15.41.mp4}
\end{center}
#+end_export
*** Center
:PROPERTIES:
:BEAMER_col: 0.33
:BEAMER_opt: [c]
:END:
#+begin_export latex
\begin{center}
East/West task
\includegraphics[width=0.9\linewidth, keepaspectratio, trim={11cm 18cm 40cm 13cm}, clip]{medias/task-east-west.png}
\end{center}
#+end_export
*** Right
:PROPERTIES:
:BEAMER_col: 0.33
:BEAMER_opt: [c]
:END:
#+begin_export latex
\begin{center}
Left/Right task
\includegraphics[width=0.9\linewidth, keepaspectratio, trim={3cm 2cm 4cm 4cm}, clip]{medias/task-left-right.jpeg}
\end{center}
#+end_export

** Deep Reinforcement Learning model
*** Left
:PROPERTIES:
:BEAMER_col: 0.5
:BEAMER_opt: [c]
:END:
#+ATTR_LaTeX: :height 0.9\textheight
[[file:medias/nn.drawio.png]]
*** Right
:PROPERTIES:
:BEAMER_col: 0.5
:BEAMER_opt: [c]
:END:
#+begin_export latex
\pause
#+end_export
- Agent learns a policy (sequences of actions) that maximize rewards
#+begin_export latex
\pause
#+end_export
- RL \to no need to have ground truth data (as in supervised learning)
** The environment
#+ATTR_LaTeX: :height 0.6\textheight
[[file:medias/RL_env-cartesian-polar.drawio.png]]
#+begin_export latex
\footnotesize
\vspace{-1em}
#+end_export
- 3 actions: $\Leftarrow \quad \Uparrow \quad \Rightarrow$
- *Duplicated* coordinates inputs:
  - Cartesian coordinates from north & south port
  - Polar coordinates from north & south port
** Questions & Hypothesis
#+begin_export latex
\metroset{block=fill}
\begin{exampleblock}{Questions}
\begin{itemize}
\footnotesize
\setlength\itemsep{0em}
\item What \alert{function} does the network learn?
\item How the constrains of the task affect learning \& the representations learned?
%\item How this task structure might employ different representations of the action space?
\item How do the representations learned compare between the \emph{in vivo} and the \emph{in silico} neurons?
\end{itemize}
\end{exampleblock}
\pause
\begin{exampleblock}{Hypothesis}
\begin{itemize}
\footnotesize
\setlength\itemsep{0em}
\item The network will use the \alert{most efficient coordinate information} (Cartesian vs. polar) based on the task (left/right vs. east/west)
\item The structure of the network's weights will reflect this prioritization of information
\item Some neurons will encode a \alert{joint representation of \{odor \& space\}} (\ie{} conjunctive cells)
\end{itemize}
\end{exampleblock}
#+end_export

* Modeling & Simulation
** State space & network architecture
#+ATTR_LaTeX: :height 0.95\textheight
[[file:medias/NN-architecture-MLP.drawio.png]]
** Training
East/West
#+ATTR_LaTeX: :height 0.35\textheight
[[file:medias/EastWest/training.png]]
Left/Right
#+ATTR_LaTeX: :height 0.35\textheight
[[file:medias/LeftRight/training.png]]
** COMMENT Agent behavior
*** Left
:PROPERTIES:
:BEAMER_col: 0.3
:BEAMER_opt: [c]
:END:
#+ATTR_LaTeX: :height 0.28\textheight
[[file:medias/trajectory-0-0-LeftRight.png]]
#+ATTR_LaTeX: :height 0.28\textheight
[[file:medias/trajectory-0-120-LeftRight.png]]
#+ATTR_LaTeX: :height 0.28\textheight
[[file:medias/trajectory-0-350-LeftRight.png]]
*** Right
:PROPERTIES:
:BEAMER_col: 0.3
:BEAMER_opt: [c]
:END:
#+ATTR_LaTeX: :height 0.28\textheight
[[file:medias/trajectory-0-0-EastWest.png]]
#+ATTR_LaTeX: :height 0.28\textheight
[[file:medias/trajectory-0-120-EastWest.png]]
#+ATTR_LaTeX: :height 0.28\textheight
[[file:medias/trajectory-0-350-EastWest.png]]
** Agent behavior
*** Left
:PROPERTIES:
:BEAMER_col: 0.33
:BEAMER_opt: [t]
:END:
#+begin_export latex
\begin{center}
\small
Naive agent\\[1em]
\movie{\includegraphics[width=\linewidth, keepaspectratio]{medias/simulations/LeftRight100to150.jpg}}{medias/simulations/LeftRight100to150.mp4}
\end{center}
#+end_export
*** Center
:PROPERTIES:
:BEAMER_col: 0.33
:BEAMER_opt: [t]
:END:
#+begin_export latex
\begin{center}
\small
Intermediate agent\\[1em]
\movie{\includegraphics[width=\linewidth, keepaspectratio]{medias/simulations/LeftRight200to250.jpg}}{medias/simulations/LeftRight200to250.mp4}
\end{center}
#+end_export
*** Right
:PROPERTIES:
:BEAMER_col: 0.33
:BEAMER_opt: [t]
:END:
#+begin_export latex
\begin{center}
\small
Trained agent\\[1em]
\movie{\includegraphics[width=\linewidth, keepaspectratio]{medias/simulations/LeftRight300to350.jpg}}{medias/simulations/LeftRight300to350.mp4}
\end{center}
#+end_export

* Results
** Pre-odor activations cluster together -- East/West
#+ATTR_LaTeX: :height 0.9\textheight
[[file:medias/activations-learned-EastWest.png]]
** Pre-odor activations cluster together -- Left/Right
#+ATTR_LaTeX: :height 0.9\textheight
[[file:medias/activations-learned-LeftRight.png]]
** PCA on activations by layer on $\{x, y\}$ coordinates -- Left/Right
#+begin_export latex
\begin{textblock}{15}(0.5, 3.5)%
\includegraphics[height=0.7\textheight, keepaspectratio]{medias/PCA-layers-activations-coords-LeftRight.png}
\vspace{-2em}
\footnotesize
\begin{itemize}
\setlength\itemsep{0em}
\item From grid shape in early layer to half moon cluster in late layers
\item Seems to encode the lower/upper triangle
\end{itemize}
\end{textblock}
#+end_export
** PCA on activations by layer on odor cue -- Left/Right
#+begin_export latex
\begin{textblock}{15}(0.2, 3.5)%
\includegraphics[height=0.68\textheight, keepaspectratio]{medias/PCA-layers-activations-cue-LeftRight.png}
\vspace{-2em}
\footnotesize
\begin{itemize}
\setlength\itemsep{0em}
\item From grid shape in early layer to half moon cluster in late layers
\item Seems that odor cues cluster by tile/grid
\end{itemize}
\end{textblock}
#+end_export
** COMMENT Use the behavior as proxy -- Perturbation experiment
:PROPERTIES:
:BEAMER_act: [<+->]
:END:
- Perturb the Cartesian/polar part of the input on a trained agent and look at how the agent behaves
- Expectation:
  - Left/right task:
    - With the *Cartesian* inputs perturbed \to agent's performance unchanged
    - With the *polar* inputs perturbed \to agent's performance degrades
  - East/west task:
    - With the *polar* inputs perturbed \to agent's performance unchanged
    - With the *Cartesian* inputs perturbed \to agent's performance degrades
** Cartesian inputs unchanged -- polar inputs perturbed
*** Left
:PROPERTIES:
:BEAMER_col: 0.5
:BEAMER_opt: [c]
:END:
#+begin_export latex
\begin{center}
\small
\textbf{East/West}\\
\footnotesize
Silencing inputs
\end{center}
#+end_export
#+ATTR_LaTeX: :width \textwidth
[[file:medias/EastWest/exp_keep-cartesian_silence-True.png]]
#+begin_export latex
\begin{center}
\footnotesize
Randomizing inputs
\end{center}
#+end_export
#+ATTR_LaTeX: :width \textwidth
[[file:medias/EastWest/exp_keep-cartesian_silence-False.png]]
*** Right
:PROPERTIES:
:BEAMER_col: 0.5
:BEAMER_opt: [c]
:END:
#+begin_export latex
\begin{center}
\small
\textbf{Left/Right}\\
\footnotesize
Silencing inputs
\end{center}
#+end_export
#+ATTR_LaTeX: :width \textwidth
[[file:medias/LeftRight/exp_keep-cartesian_silence-True.png]]
#+begin_export latex
\begin{center}
\footnotesize
Randomizing inputs
\end{center}
#+end_export
#+ATTR_LaTeX: :width \textwidth
[[file:medias/LeftRight/exp_keep-cartesian_silence-False.png]]
** Polar inputs unchanged -- Cartesian inputs perturbed
*** Left
:PROPERTIES:
:BEAMER_col: 0.5
:BEAMER_opt: [c]
:END:
#+begin_export latex
\begin{center}
\small
\textbf{East/West}\\
\footnotesize
Silencing inputs
\end{center}
#+end_export
#+ATTR_LaTeX: :width \textwidth
[[file:medias/EastWest/exp_keep-polar_silence-True.png]]
#+begin_export latex
\begin{center}
\footnotesize
Randomizing inputs
\end{center}
#+end_export
#+ATTR_LaTeX: :width \textwidth
[[file:medias/EastWest/exp_keep-polar_silence-False.png]]
*** Right
:PROPERTIES:
:BEAMER_col: 0.5
:BEAMER_opt: [c]
:END:
#+begin_export latex
\begin{center}
\small
\textbf{Left/Right}\\
\footnotesize
Silencing inputs
\end{center}
#+end_export
#+ATTR_LaTeX: :width \textwidth
[[file:medias/LeftRight/exp_keep-polar_silence-True.png]]
#+begin_export latex
\begin{center}
\footnotesize
Randomizing inputs
\end{center}
#+end_export
#+ATTR_LaTeX: :width \textwidth
[[file:medias/LeftRight/exp_keep-polar_silence-False.png]]
** COMMENT Bottleneck network (1/2)
#+begin_export latex
\center
\begin{tikzpicture}
    \node[anchor=south west,inner sep=0] (image) at (0,0) {\includegraphics[height=0.95\textheight]{medias/NN-architecture-bottleneck.drawio.png}};
    \draw[RedBrown,ultra thick,rounded corners] (5.2,3) rectangle (6.2,5.5);
\end{tikzpicture}
#+end_export
** Bottleneck network \to performance degrades below $\sim\!10$ neurons
#+ATTR_LaTeX: :height 0.4\textheight
[[file:medias/NN-architecture-bottleneck.drawio.png]]
#+begin_export latex
\vspace{-3em}
#+end_export

*** Left
:PROPERTIES:
:BEAMER_col: 0.5
:BEAMER_opt: [c]
:END:
#+begin_export latex
\begin{center}
\small
\textbf{East/West}\\
\end{center}
#+end_export
#+ATTR_LaTeX: :width 0.9\textwidth
[[file:medias/steps-boxplot-EastWest.png]]

*** Right
:PROPERTIES:
:BEAMER_col: 0.5
:BEAMER_opt: [c]
:END:
#+begin_export latex
\begin{center}
\small
\textbf{Left/Right}\\
\end{center}
#+end_export
#+ATTR_LaTeX: :width 0.9\textwidth
[[file:medias/steps-boxplot-LeftRight.png]]
* Conclusion
** Partial conclusions so far
:PROPERTIES:
:BEAMER_act: [<+->]
:END:
- Hierarchical clustering \to the *pre-odor activations* cluster together, but no other clear pattern seems to emerge
- Dimensionality reduction analysis \to the network seems to mainly encode the *position of the agent on the grid*
- With this task setup, it seems *both types of coordinates information are required* to solve the task \to is this a negative result that invalidates our original hypothesis or is this due to overfitting?
  - From earlier experiments, we know the agent can perfectly solve the task without needing duplicated inputs$\text{\dots}$
** Next steps
:PROPERTIES:
:BEAMER_act: [<+->]
:END:
- What happens in between tiles? Did the network learn to *interpolate*?
- Add *dropout* during training to make the network more robust to perturbations and avoid overfitting?
- Identify the potential functions of the neurons in the bottleneck layer? What type of information do they encode? Any sign of potential *conjunctive cells*?
- End of this project \to still looking for well defined results/principles/rules for a potential MVP (Minimum Viable Publication)

** \nbsp{}
:PROPERTIES:
:BEAMER_opt: standout
:END:
Questions ?
* Appendix
:PROPERTIES:
:BEAMER_ENV: appendix
:END:
#+begin_export latex
\begin{frame}[fragile]{Pytorch network}
\addtocounter{framenumber}{-1}
\scriptsize
\begin{lstlisting}
DQN(
  (mlp): Sequential(
    (0): Linear(in_features=21, out_features=512, bias=True)
    (1): Linear(in_features=512, out_features=512, bias=True)
    (2): ReLU()
    (3): Linear(in_features=512, out_features=512, bias=True)
    (4): ReLU()
    (5): Linear(in_features=512, out_features=512, bias=True)
    (6): ReLU()
    (7): Linear(in_features=512, out_features=3, bias=True)
  )
)
\end{lstlisting}
\end{frame}
#+end_export
* COMMENT Add plain option to Beamer TOC
% Local variables:
% org-beamer-outline-frame-options: "plain"
% End:

* Feedback :noexport:
** Derive of any input wrt input
*** Avg over playback of the agent
*** How sensitive is the agent for this task
** TODO Perturbation
*** TODO 15 deg rotation
*** Inject the expected mean
*** Instead of randomize, just add some noise
*** Check sensitivity of the input
**** Translate a little bit the input until it doesn't work anymore
** How do these representations change across learning?
** What representation do you learn under certain form of constrains?
** Lines between PCA dots
** Variations between agents?
** PCA across training
*** More direct representations?
** SHAP feature importance
*** Cartesian vs polar favored in some location on the grid?
